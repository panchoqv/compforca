{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'plyr' was built under R version 3.3.3\"Warning message:\n",
      "\"package 'tidyverse' was built under R version 3.3.3\"Loading tidyverse: ggplot2\n",
      "Loading tidyverse: tibble\n",
      "Loading tidyverse: tidyr\n",
      "Loading tidyverse: readr\n",
      "Loading tidyverse: purrr\n",
      "Loading tidyverse: dplyr\n",
      "Warning message:\n",
      "\"package 'ggplot2' was built under R version 3.3.3\"Warning message:\n",
      "\"package 'tibble' was built under R version 3.3.3\"Warning message:\n",
      "\"package 'tidyr' was built under R version 3.3.3\"Warning message:\n",
      "\"package 'readr' was built under R version 3.3.3\"Warning message:\n",
      "\"package 'purrr' was built under R version 3.3.3\"Warning message:\n",
      "\"package 'dplyr' was built under R version 3.3.3\"Conflicts with tidy packages ---------------------------------------------------\n",
      "arrange():   dplyr, plyr\n",
      "compact():   purrr, plyr\n",
      "count():     dplyr, plyr\n",
      "failwith():  dplyr, plyr\n",
      "filter():    dplyr, stats\n",
      "id():        dplyr, plyr\n",
      "lag():       dplyr, stats\n",
      "mutate():    dplyr, plyr\n",
      "rename():    dplyr, plyr\n",
      "summarise(): dplyr, plyr\n",
      "summarize(): dplyr, plyr\n",
      "Warning message:\n",
      "\"package 'DT' was built under R version 3.3.3\"Warning message:\n",
      "\"package 'ggthemes' was built under R version 3.3.3\"Warning message:\n",
      "\"package 'DescTools' was built under R version 3.3.3\"Parsed with column specification:\n",
      "cols(\n",
      "  .default = col_double(),\n",
      "  userId = col_character(),\n",
      "  age = col_character(),\n",
      "  datetime = col_character(),\n",
      "  gender = col_character(),\n",
      "  datetime_1 = col_character(),\n",
      "  stage = col_integer(),\n",
      "  scenario = col_character(),\n",
      "  subcondition = col_integer(),\n",
      "  pageIndex = col_integer(),\n",
      "  noiseIndex = col_integer(),\n",
      "  day0 = col_character(),\n",
      "  day1 = col_character(),\n",
      "  day2 = col_character(),\n",
      "  day3 = col_character(),\n",
      "  day4 = col_character(),\n",
      "  day5 = col_character(),\n",
      "  day6 = col_character(),\n",
      "  day7 = col_character(),\n",
      "  day8 = col_character(),\n",
      "  day9 = col_character()\n",
      "  # ... with 69 more columns\n",
      ")\n",
      "See spec(...) for full column specifications.\n",
      "Warning message:\n",
      "\"package 'bindrcpp' was built under R version 3.3.3\"Warning message in eval(substitute(expr), envir, enclos):\n",
      "\"NAs introduced by coercion\""
     ]
    }
   ],
   "source": [
    "source(\"tools.R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'gridExtra' was built under R version 3.3.3\"\n",
      "Attaching package: 'gridExtra'\n",
      "\n",
      "The following object is masked from 'package:dplyr':\n",
      "\n",
      "    combine\n",
      "\n",
      "Warning message:\n",
      "\"package 'lsr' was built under R version 3.3.2\""
     ]
    }
   ],
   "source": [
    "library(gridExtra)\n",
    "library(lsr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bootstrapped confidence interval (for binomial distribution).\n",
    "\n",
    "NOTE: Do you like this method Eric? Or should we use a package [like this one](http://math.furman.edu/~dcs/courses/math47/R/library/Hmisc/html/binconf.html)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bp = function(x, lev, n = 1e4, alpha=0.05) {\n",
    "  res = replicate(n, sum(sample(x, length(x), replace=TRUE) == lev)/length(x))\n",
    "  return(list(mean=mean(res),\n",
    "              `95% CI`=quantile(res, c(0.5*alpha,1-0.5*alpha))))\n",
    "}\n",
    "\n",
    "bp2 = function(vector, n = 1e4, alpha=0.05, round_n=2) {\n",
    "    \n",
    "    match_ci <- bp(x=vector, lev=TRUE, n=n, alpha=alpha)\n",
    "    \n",
    "    return( c( match_ci$mean %>% round(round_n),\n",
    "             match_ci$`95% CI`[1] %>% round(round_n),\n",
    "             match_ci$`95% CI`[2] %>% round(round_n) ))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "standardize_range_one <- function(array) {\n",
    "    (array - min(array)) / (max(array) - min(array))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Kernel composition name change\n",
    "#l+r+p -> l+p+r\n",
    "#l+r*p -> l+p*r\n",
    "#l*r*p -> l*p*r\n",
    "\n",
    "readable_kernel <- function(current_kernel){\n",
    "    new_kernel <- current_kernel\n",
    "    \n",
    "    new_kernel <- ifelse(new_kernel == 'l+r+p', 'l+p+r', new_kernel)\n",
    "    new_kernel <- ifelse(new_kernel == 'l+r*p', 'l+p*r', new_kernel)\n",
    "    new_kernel <- ifelse(new_kernel == 'l*r*p', 'l*p*r', new_kernel)\n",
    "    \n",
    "    new_kernel <- gsub(\"\\\\*\", \"×\", new_kernel)\n",
    "    \n",
    "    return(new_kernel)\n",
    "}\n",
    "\n",
    "# Get the range of a scenario\n",
    "get_range <- function(scenario_name) {\n",
    "    switch( scenario_name,\n",
    "            'Temperature' = c(-10, 40),\n",
    "            'Rain' = c(0, 100),\n",
    "            'Sales' = c(0, 5000),\n",
    "            'Gym members' = c(0, 50),\n",
    "            'Salary' = c(0, 50),\n",
    "            'FB Friends' = c(0, 1000))\n",
    "}\n",
    "\n",
    "kernels    <- c(\"l\", \"p\", \"r\", \"l+p\", \"l+r\", \"p+r\", \"l*r\", \"l*p\", \"p*r\", \"l+r+p\", \"l+r*p\", \"l*r+p\", \"l*p+r\", \"l*r*p\")\n",
    "\n",
    "kernels_2  <- c(\"l\", \"p\", \"r\", \"l+p\", \"l+r\", \"p+r\", \"l×r\", \"l×p\", \"p×r\", \"l+p+r\", \"l+p×r\", \"l×r+p\", \"l×p+r\", \"l×p×r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_lmls <- function(prop_data, title='', scenario, hide_x=FALSE, hide_y=FALSE, red_border=TRUE) {\n",
    "    \n",
    "    # Best-fitting real-world data kernel composition\n",
    "    rw_lmls <- read_csv(\"data/real-world/to-plot.csv\")\n",
    "    red_kernel <- (rw_lmls %>%\n",
    "                    filter(kernel != 'l', kernel != 'p', kernel != 'r') %>%\n",
    "                    filter(scenario == !!scenario) %>%\n",
    "                    summarize(red_kernel = kernel[which.max(lml)]))$red_kernel\n",
    "    red_kernel <- readable_kernel(red_kernel)\n",
    "\n",
    "    plot <- prop_data %>%\n",
    "                ggplot(aes(x=kernel, y=value)) +\n",
    "                    geom_bar(stat='identity') +\n",
    "                    geom_bar(stat='identity', data=prop_data %>% filter(kernel == red_kernel), alpha=0, size=0.5, color=\"red\") +\n",
    "                    coord_cartesian (ylim=c(0, 1)) +\n",
    "                    #labs(title = title) +\n",
    "                    ggthemes::theme_few() +\n",
    "                    xlab(\"Kernel composition\") +\n",
    "                    ylab(\"Likelihood\") +\n",
    "                    geom_errorbar(aes(ymin=as.numeric(lo_ci), ymax=as.numeric(hi_ci)),\n",
    "                                      width=.3,\n",
    "                                      position=position_dodge(.9)) +\n",
    "                    scale_y_continuous(breaks = seq(0, 1, length.out=3)) +\n",
    "                    theme(axis.text.x = element_text(angle = 90,  vjust = 0.5, hjust=0),\n",
    "                          text = element_text(size=12, family=\"serif\"))\n",
    "\n",
    "    if(hide_x){\n",
    "        plot <- plot + theme(axis.title.x=element_blank())\n",
    "    }\n",
    "    if(hide_y){\n",
    "        plot <- plot + theme(axis.title.y=element_blank())\n",
    "    }\n",
    "    \n",
    "    return(plot)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_curves <- function(plot_data, plot_rwdata, ylab='', scenario, hide_x=FALSE, hide_y=FALSE) {\n",
    "\n",
    "    # Min and max value of the data to be shown\n",
    "    range_y <- get_range(scenario)\n",
    "    limits_y <- c( min(range_y[1], min(plot_data$value)), max(range_y[2], max(plot_data$value)))\n",
    "    \n",
    "    # Mean trend\n",
    "    trend <- plot_data %>% group_by(day) %>% summarize(mean_y = mean(value))\n",
    "    \n",
    "    # Resolution subsetting\n",
    "    resolution = 10 #smaller number is higher resolution\n",
    "    plot_data <- plot_data %>% filter((day - min(day)) %% resolution == 0)\n",
    "    trend <- trend %>% filter((day - min(day)) %% resolution == 0)\n",
    "    \n",
    "    # Plotting\n",
    "    plot <- plot_data %>%\n",
    "                ggplot(aes(x=day, y=value, group=id)) +\n",
    "                    geom_line(col=\"steelblue\", alpha=0.2) + # Participants' curves\n",
    "                    geom_line(data=plot_rwdata, aes(x=day, group=1), colour=\"red\", alpha=0.6) + # Real world data\n",
    "                    geom_line(data=trend, aes(x=day, y=mean_y, group=1), colour=\"black\") + # Mean trend\n",
    "                    #labs(title = title) +\n",
    "                    ggthemes::theme_few() +\n",
    "                    ylab(ylab) +\n",
    "                    scale_x_continuous(breaks = c(0, 365, 365*2, 365*3), labels=c('Y1', 'Y2', 'Y3', 'Y4')) +\n",
    "                    scale_y_continuous(breaks = seq(range_y[1], range_y[2], length.out=3), limits=limits_y) +\n",
    "                    theme(axis.text.x = element_text(angle = 90,  vjust = 0.5, hjust=0),\n",
    "                          axis.text.y = element_text(angle = 90,  vjust = 0.5, hjust=0.5),\n",
    "                          text = element_text(size=12, family=\"serif\"))\n",
    "\n",
    "    if(hide_x){\n",
    "        plot <- plot + theme(axis.title.x=element_blank())\n",
    "    }\n",
    "    if(hide_y){\n",
    "        plot <- plot + theme(axis.title.y=element_blank())\n",
    "    }\n",
    "    \n",
    "    return(plot)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior: Kernel compositions bar plots\n",
    "\n",
    "##### Import and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"Missing column names filled in: 'X1' [1]\"Parsed with column specification:\n",
      "cols(\n",
      "  X1 = col_integer(),\n",
      "  id = col_integer(),\n",
      "  pid = col_character(),\n",
      "  scenario = col_character(),\n",
      "  x = col_integer(),\n",
      "  y = col_double()\n",
      ")\n",
      "Parsed with column specification:\n",
      "cols(\n",
      "  cid = col_integer(),\n",
      "  kernel = col_character(),\n",
      "  lml = col_double(),\n",
      "  white_added = col_character(),\n",
      "  second_exception = col_character()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data_prior <- read_csv(\"data/for_composititional_analysis_prior.csv\")\n",
    "\n",
    "# Get a \"dictionary\" of ID, PID, Scenario\n",
    "dict_prior <- data_prior %>%                        \n",
    "                        group_by(id, pid, scenario) %>%\n",
    "                        summarize()\n",
    "\n",
    "# Get the results of the LML analysis over the prior data\n",
    "prior_results <- read_csv('output/minus-mean-treatment/results_prior_lmls.csv')\n",
    "\n",
    "# Merge the results with the dictionary to have a 'full view' of the situation\n",
    "lmls_prior <- merge(prior_results, dict_prior, by.x='cid', by.y='id', all.x=TRUE)\n",
    "\n",
    "# Kernel composition name change\n",
    "lmls_prior$kernel <- readable_kernel(lmls_prior$kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removes the GPs that failed to be optimized in the second time. The lmls that failed to be optimized are also removed.\n",
    "#Finaly, the lml_standard is calculated\n",
    "lmls_prior_f <- lmls_prior %>%\n",
    "                    filter(kernel != 'l', kernel != 'p', kernel != 'r') %>%\n",
    "                    filter(second_exception == 'False' & lml != -999999999)\n",
    "\n",
    "sds <- lmls_prior_f %>% \n",
    "            group_by(kernel, scenario) %>%\n",
    "            summarize(lo_bound = mean(lml) - 5*sd(lml), up_bound = mean(lml) + 5*sd(lml))\n",
    "\n",
    "sds$ks <- paste0(sds$kernel, sds$scenario)\n",
    "\n",
    "lmls_prior_f$ks <- paste0(lmls_prior_f$kernel, lmls_prior_f$scenario)\n",
    "\n",
    "sds$kernel <- NULL\n",
    "sds$scenario <- NULL\n",
    "\n",
    "lmls_prior_f <- merge(x = lmls_prior_f, y = sds, by = \"ks\", all.x = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  scenario = col_character(),\n",
      "  kernel = col_character(),\n",
      "  lml = col_double()\n",
      ")\n",
      "Parsed with column specification:\n",
      "cols(\n",
      "  scenario = col_character(),\n",
      "  kernel = col_character(),\n",
      "  lml = col_double()\n",
      ")\n",
      "Parsed with column specification:\n",
      "cols(\n",
      "  scenario = col_character(),\n",
      "  kernel = col_character(),\n",
      "  lml = col_double()\n",
      ")\n",
      "Parsed with column specification:\n",
      "cols(\n",
      "  scenario = col_character(),\n",
      "  kernel = col_character(),\n",
      "  lml = col_double()\n",
      ")\n",
      "Parsed with column specification:\n",
      "cols(\n",
      "  scenario = col_character(),\n",
      "  kernel = col_character(),\n",
      "  lml = col_double()\n",
      ")\n",
      "Parsed with column specification:\n",
      "cols(\n",
      "  scenario = col_character(),\n",
      "  kernel = col_character(),\n",
      "  lml = col_double()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "plot_bool      = TRUE\n",
    "\n",
    "lmls_prior_ff <- lmls_prior_f %>%\n",
    "            filter(lml > lo_bound & lml < up_bound)\n",
    "\n",
    "# Remove single components AND for each participant-scenario combination, make a 0 to 1 range\n",
    "to_plot_prior <- lmls_prior_ff %>%\n",
    "                    group_by( pid, scenario ) %>%\n",
    "                    mutate( lml = standardize_range_one(lml) )\n",
    "\n",
    "# Produce means and confidence intervals\n",
    "to_plot_prior <- to_plot_prior %>%\n",
    "            group_by(kernel, scenario) %>%\n",
    "            summarize(value = mean(lml),\n",
    "                      lo_ci = MeanCI(lml, method=\"boot\", type=\"norm\", na.rm=TRUE)['lwr.ci'],\n",
    "                      hi_ci = MeanCI(lml, method=\"boot\", type=\"norm\", na.rm=TRUE)['upr.ci'])\n",
    "\n",
    "# Plotting magic\n",
    "to_plot_prior$kernel <- factor(to_plot_prior$kernel, levels=readable_kernel(kernels))\n",
    "\n",
    "\n",
    "if (plot_bool) {\n",
    "    # Plots\n",
    "    p_temp   <- plot_lmls( to_plot_prior %>% filter(scenario == \"Temperature\"), scenario=\"Temperature\", hide_x=TRUE, hide_y=FALSE)\n",
    "    p_rain   <- plot_lmls( to_plot_prior %>% filter(scenario == \"Rain\"),        scenario=\"Rain\",        hide_x=TRUE, hide_y=FALSE)\n",
    "    p_sales  <- plot_lmls( to_plot_prior %>% filter(scenario == \"Sales\"),       scenario=\"Sales\",       hide_x=TRUE, hide_y=FALSE)\n",
    "    p_gym    <- plot_lmls( to_plot_prior %>% filter(scenario == \"Gym members\"), scenario=\"Gym members\", hide_x=TRUE, hide_y=FALSE)\n",
    "    p_salary <- plot_lmls( to_plot_prior %>% filter(scenario == \"Salary\"),      scenario=\"Salary\",      hide_x=TRUE, hide_y=FALSE)\n",
    "    p_fb     <- plot_lmls( to_plot_prior %>% filter(scenario == \"FB Friends\"),  scenario=\"FB Friends\",  hide_x=TRUE, hide_y=FALSE)\n",
    "\n",
    "    #pdf(\"Images/paper_images/kernels_priors_lmls_5sd.pdf\", width=8, height=4)\n",
    "    #multiplot(p1, p2, p3, p4, p5, p6, cols=3)\n",
    "    #dev.off()   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests for Prior condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best fitting kernel compositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>scenario</th><th scope=col>composition</th><th scope=col>value</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Temperature</td><td>p×r        </td><td>0.9192010  </td></tr>\n",
       "\t<tr><td>Rain       </td><td>p×r        </td><td>0.9185013  </td></tr>\n",
       "\t<tr><td>Sales      </td><td>l+r        </td><td>0.9652802  </td></tr>\n",
       "\t<tr><td>Gym members</td><td>p×r        </td><td>0.8959303  </td></tr>\n",
       "\t<tr><td>Salary     </td><td>l+r        </td><td>0.8576757  </td></tr>\n",
       "\t<tr><td>FB Friends </td><td>l+r        </td><td>0.9315774  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " scenario & composition & value\\\\\n",
       "\\hline\n",
       "\t Temperature & p×r         & 0.9192010  \\\\\n",
       "\t Rain        & p×r         & 0.9185013  \\\\\n",
       "\t Sales       & l+r         & 0.9652802  \\\\\n",
       "\t Gym members & p×r         & 0.8959303  \\\\\n",
       "\t Salary      & l+r         & 0.8576757  \\\\\n",
       "\t FB Friends  & l+r         & 0.9315774  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "scenario | composition | value | \n",
       "|---|---|---|---|---|---|\n",
       "| Temperature | p×r         | 0.9192010   | \n",
       "| Rain        | p×r         | 0.9185013   | \n",
       "| Sales       | l+r         | 0.9652802   | \n",
       "| Gym members | p×r         | 0.8959303   | \n",
       "| Salary      | l+r         | 0.8576757   | \n",
       "| FB Friends  | l+r         | 0.9315774   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  scenario    composition value    \n",
       "1 Temperature p×r         0.9192010\n",
       "2 Rain        p×r         0.9185013\n",
       "3 Sales       l+r         0.9652802\n",
       "4 Gym members p×r         0.8959303\n",
       "5 Salary      l+r         0.8576757\n",
       "6 FB Friends  l+r         0.9315774"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>scenario</th><th scope=col>composition</th><th scope=col>value</th><th scope=col>lo_ci</th><th scope=col>hi_ci</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Temperature</td><td>p×r        </td><td>0.9192010  </td><td>0.8801756  </td><td>0.9575137  </td></tr>\n",
       "\t<tr><td>Rain       </td><td>p×r        </td><td>0.9185013  </td><td>0.8819013  </td><td>0.9543502  </td></tr>\n",
       "\t<tr><td>Rain       </td><td>l+r        </td><td>0.8727970  </td><td>0.8468486  </td><td>0.8995264  </td></tr>\n",
       "\t<tr><td>Rain       </td><td>l+p×r      </td><td>0.8647992  </td><td>0.8251855  </td><td>0.9047734  </td></tr>\n",
       "\t<tr><td>Sales      </td><td>l+r        </td><td>0.9652802  </td><td>0.9498349  </td><td>0.9801867  </td></tr>\n",
       "\t<tr><td>Gym members</td><td>p×r        </td><td>0.8959303  </td><td>0.8574413  </td><td>0.9348408  </td></tr>\n",
       "\t<tr><td>Salary     </td><td>l+r        </td><td>0.8576757  </td><td>0.8165901  </td><td>0.8967853  </td></tr>\n",
       "\t<tr><td>Salary     </td><td>p+r        </td><td>0.8078211  </td><td>0.7526040  </td><td>0.8627519  </td></tr>\n",
       "\t<tr><td>FB Friends </td><td>l+r        </td><td>0.9315774  </td><td>0.9160463  </td><td>0.9476402  </td></tr>\n",
       "\t<tr><td>FB Friends </td><td>l+p×r      </td><td>0.8974742  </td><td>0.8688241  </td><td>0.9273888  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " scenario & composition & value & lo\\_ci & hi\\_ci\\\\\n",
       "\\hline\n",
       "\t Temperature & p×r         & 0.9192010   & 0.8801756   & 0.9575137  \\\\\n",
       "\t Rain        & p×r         & 0.9185013   & 0.8819013   & 0.9543502  \\\\\n",
       "\t Rain        & l+r         & 0.8727970   & 0.8468486   & 0.8995264  \\\\\n",
       "\t Rain        & l+p×r       & 0.8647992   & 0.8251855   & 0.9047734  \\\\\n",
       "\t Sales       & l+r         & 0.9652802   & 0.9498349   & 0.9801867  \\\\\n",
       "\t Gym members & p×r         & 0.8959303   & 0.8574413   & 0.9348408  \\\\\n",
       "\t Salary      & l+r         & 0.8576757   & 0.8165901   & 0.8967853  \\\\\n",
       "\t Salary      & p+r         & 0.8078211   & 0.7526040   & 0.8627519  \\\\\n",
       "\t FB Friends  & l+r         & 0.9315774   & 0.9160463   & 0.9476402  \\\\\n",
       "\t FB Friends  & l+p×r       & 0.8974742   & 0.8688241   & 0.9273888  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "scenario | composition | value | lo_ci | hi_ci | \n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| Temperature | p×r         | 0.9192010   | 0.8801756   | 0.9575137   | \n",
       "| Rain        | p×r         | 0.9185013   | 0.8819013   | 0.9543502   | \n",
       "| Rain        | l+r         | 0.8727970   | 0.8468486   | 0.8995264   | \n",
       "| Rain        | l+p×r       | 0.8647992   | 0.8251855   | 0.9047734   | \n",
       "| Sales       | l+r         | 0.9652802   | 0.9498349   | 0.9801867   | \n",
       "| Gym members | p×r         | 0.8959303   | 0.8574413   | 0.9348408   | \n",
       "| Salary      | l+r         | 0.8576757   | 0.8165901   | 0.8967853   | \n",
       "| Salary      | p+r         | 0.8078211   | 0.7526040   | 0.8627519   | \n",
       "| FB Friends  | l+r         | 0.9315774   | 0.9160463   | 0.9476402   | \n",
       "| FB Friends  | l+p×r       | 0.8974742   | 0.8688241   | 0.9273888   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   scenario    composition value     lo_ci     hi_ci    \n",
       "1  Temperature p×r         0.9192010 0.8801756 0.9575137\n",
       "2  Rain        p×r         0.9185013 0.8819013 0.9543502\n",
       "3  Rain        l+r         0.8727970 0.8468486 0.8995264\n",
       "4  Rain        l+p×r       0.8647992 0.8251855 0.9047734\n",
       "5  Sales       l+r         0.9652802 0.9498349 0.9801867\n",
       "6  Gym members p×r         0.8959303 0.8574413 0.9348408\n",
       "7  Salary      l+r         0.8576757 0.8165901 0.8967853\n",
       "8  Salary      p+r         0.8078211 0.7526040 0.8627519\n",
       "9  FB Friends  l+r         0.9315774 0.9160463 0.9476402\n",
       "10 FB Friends  l+p×r       0.8974742 0.8688241 0.9273888"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "to_plot_prior %>%\n",
    "    group_by(scenario) %>%\n",
    "    summarize(composition = kernel[which.max(value)], value = value[which.max(value)]) %>%\n",
    "    arrange(scenarios_order(scenario))\n",
    "\n",
    "# Which other kernel compositions are statistically equivalent\n",
    "to_plot_prior %>%\n",
    "    group_by(scenario) %>%\n",
    "    filter(hi_ci > lo_ci[which.max(value)]) %>%\n",
    "    select(scenario, composition = kernel, value, lo_ci, hi_ci) %>%\n",
    "    arrange(scenarios_order(scenario), -value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percentage of removed GPs in the Prior condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "5.02"
      ],
      "text/latex": [
       "5.02"
      ],
      "text/markdown": [
       "5.02"
      ],
      "text/plain": [
       "[1] 5.02"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Percentage of removed GPs in the Prior condition:\n",
    "((1 -\n",
    "lmls_prior_ff %>%\n",
    "    filter(kernel != 'l', kernel != 'p', kernel != 'r') %>%\n",
    "    nrow / \n",
    "lmls_prior %>%\n",
    "    filter(kernel != 'l', kernel != 'p', kernel != 'r') %>%\n",
    "    nrow) * 100) %>%\n",
    "round(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking correlation: participants -> real-world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  scenario = col_character(),\n",
      "  kernel = col_character(),\n",
      "  lml = col_double()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get the real world data and make it readable\n",
    "to_merge_rw_lmls <- read_csv(\"data/real-world/to-plot.csv\")\n",
    "to_merge_rw_lmls$kernel <- readable_kernel(to_merge_rw_lmls$kernel)\n",
    "\n",
    "# Filter out the non-compositional kernels\n",
    "to_merge_rw_lmls <- to_merge_rw_lmls %>% \n",
    "                filter(kernel != 'l', kernel != 'p', kernel != 'r')\n",
    "\n",
    "# Raw prior data: lmls_prior \n",
    "to_merge_lmls_prior <- lmls_prior_ff %>% filter(kernel != 'l', kernel != 'p', kernel != 'r')\n",
    "\n",
    "# Merging the real world data with the prior results\n",
    "lmls_prior_new <- merge(x = to_merge_lmls_prior, \n",
    "                        y = to_merge_rw_lmls,\n",
    "                        by = c('scenario', 'kernel'),\n",
    "                        suffixes = c(\"_participants\",\"_real_world\")\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Per scenario\"\n",
      "[1] \"Overall\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\tOne Sample t-test\n",
       "\n",
       "data:  dcor2$r\n",
       "t = 13.912, df = 118, p-value < 2.2e-16\n",
       "alternative hypothesis: true mean is not equal to 0\n",
       "95 percent confidence interval:\n",
       " 0.1184958 0.1578284\n",
       "sample estimates:\n",
       "mean of x \n",
       "0.1381621 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1.28"
      ],
      "text/latex": [
       "1.28"
      ],
      "text/markdown": [
       "1.28"
      ],
      "text/plain": [
       "[1] 1.28"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the rank correlation\n",
    "print('Per scenario')\n",
    "\n",
    "dcor1 <- ddply(lmls_prior_new, ~scenario+pid, summarize, r=cor(rank(lml_participants), rank(lml_real_world)))\n",
    "\n",
    "dout <- ddply(dcor1, ~scenario, summarize, m=cohensD(r))\n",
    "test_results_per_scenario <- tapply(dcor1$r, dcor1$scenario, t.test)\n",
    "\n",
    "\n",
    "print('Overall')\n",
    "\n",
    "dcor2 <- ddply(lmls_prior_new, ~pid, summarize, r=cor(rank(lml_participants), rank(lml_real_world)))\n",
    "\n",
    "t.test(dcor2$r)\n",
    "cohensD(dcor2$r) %>% round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_test_results <- function(scenario_name, readable_s_name){\n",
    "    df <- test_results_per_scenario[[scenario_name]][[2]]\n",
    "    p_val <- ifelse(test_results_per_scenario[[scenario_name]][[3]] < 0.001, \n",
    "                \"<0.001\", \n",
    "                test_results_per_scenario[[scenario_name]][[3]])\n",
    "    t <- test_results_per_scenario[[scenario_name]][[1]] %>% round(2)\n",
    "\n",
    "    d_val <- (dout %>% filter(scenario == scenario_name))$m %>% round(2)\n",
    "\n",
    "    rho <- test_results_per_scenario[[scenario_name]][[5]] %>% round(2)\n",
    "    \n",
    "    t_string <- paste0(\", $\\rho=\", rho,\"$\", \" ($t(\", df, \")=\", t, \", p\", p_val, \", d=\", d_val, \"$)\")\n",
    "    \n",
    "    paste0(t_string, \" for the \", readable_s_name, \" data\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \", $\\rho=0.61$ ($t(118)=32.26, p<0.001, d=2.96$) for the Temperature data, $\\rho=0.58$ ($t(118)=24.63, p<0.001, d=2.26$) for the Rain data, $\\rho=0.48$ ($t(118)=20.23, p<0.001, d=1.85$) for the Sales data, $\\rho=0.16$ ($t(118)=6.41, p<0.001, d=0.59$) for the Gym members data, $\\rho=0.61$ ($t(118)=37.3, p<0.001, d=3.42$) for the Salary data, $\\rho=0.62$ ($t(118)=33.62, p<0.001, d=3.08$) for the Facebook friends data\"\n"
     ]
    }
   ],
   "source": [
    "paste0(  print_test_results('Temperature', 'Temperature'),\n",
    "        print_test_results('Rain', 'Rain'),\n",
    "        print_test_results('Sales', 'Sales'),\n",
    "        print_test_results('Gym members', 'Gym members'),\n",
    "        print_test_results('Salary', 'Salary'),\n",
    "        print_test_results('FB Friends', 'Facebook friends')) %>% print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation per scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"All should be TRUE:\"\n",
      "   lml_real_world\n",
      "56           TRUE\n",
      "57           TRUE\n",
      "58           TRUE\n",
      "59           TRUE\n",
      "60           TRUE\n",
      "61           TRUE\n",
      "62           TRUE\n",
      "63           TRUE\n",
      "64           TRUE\n",
      "65           TRUE\n",
      "66           TRUE\n",
      "[1] \"All should be TRUE:\"\n",
      "   lml_real_world\n",
      "56           TRUE\n",
      "57           TRUE\n",
      "58           TRUE\n",
      "59           TRUE\n",
      "60           TRUE\n",
      "61           TRUE\n",
      "62           TRUE\n",
      "63           TRUE\n",
      "64           TRUE\n",
      "65           TRUE\n",
      "66           TRUE\n",
      "[1] \"All should be TRUE:\"\n",
      "   lml_real_world\n",
      "56           TRUE\n",
      "57           TRUE\n",
      "58           TRUE\n",
      "59           TRUE\n",
      "60           TRUE\n",
      "61           TRUE\n",
      "62           TRUE\n",
      "63           TRUE\n",
      "64           TRUE\n",
      "65           TRUE\n",
      "66           TRUE\n",
      "[1] \"All should be TRUE:\"\n",
      "   lml_real_world\n",
      "56           TRUE\n",
      "57           TRUE\n",
      "58           TRUE\n",
      "59           TRUE\n",
      "60           TRUE\n",
      "61           TRUE\n",
      "62           TRUE\n",
      "63           TRUE\n",
      "64           TRUE\n",
      "65           TRUE\n",
      "66           TRUE\n",
      "[1] \"All should be TRUE:\"\n",
      "   lml_real_world\n",
      "56           TRUE\n",
      "57           TRUE\n",
      "58           TRUE\n",
      "59           TRUE\n",
      "60           TRUE\n",
      "61           TRUE\n",
      "62           TRUE\n",
      "63           TRUE\n",
      "64           TRUE\n",
      "65           TRUE\n",
      "66           TRUE\n",
      "[1] \"All should be TRUE:\"\n",
      "   lml_real_world\n",
      "56           TRUE\n",
      "57           TRUE\n",
      "58           TRUE\n",
      "59           TRUE\n",
      "60           TRUE\n",
      "61           TRUE\n",
      "62           TRUE\n",
      "63           TRUE\n",
      "64           TRUE\n",
      "65           TRUE\n",
      "66           TRUE\n"
     ]
    }
   ],
   "source": [
    "# Initial variables\n",
    "cross_lmls_prior <- lmls_prior_new\n",
    "cross_scenarios <- sort(readable_scenarios) \n",
    "cross_scenarios_init <- sort(readable_scenarios) \n",
    "\n",
    "results <- data.frame(col1 = character(), col2 = character(), col3 = double())\n",
    "colnames(results) <- c('real_world_scenario', 'explained_by_participants_scenario', 'rho')\n",
    "\n",
    "#### Begin cycle ####\n",
    "y = 0\n",
    "while(y < 6){\n",
    "    \n",
    "    y = y + 1\n",
    "\n",
    "    # For the later validation\n",
    "    cross_lmls_prior_initial <- cross_lmls_prior \n",
    "\n",
    "    # Grouping and sorting\n",
    "    real_world_lmls <- cross_lmls_prior %>%\n",
    "                        select(scenario, kernel, lml_real_world) %>%\n",
    "                        unique %>%\n",
    "                        arrange(scenario, kernel)\n",
    "\n",
    "    # Round robin\n",
    "    new_lmls_round_robin <- c( real_world_lmls$lml_real_world[12:66], \n",
    "                               real_world_lmls$lml_real_world[1:11] )\n",
    "\n",
    "    # Round robin in the name of the scenarios (to interpret the results)\n",
    "    cross_scenarios <- c(cross_scenarios[2:6], cross_scenarios[1])\n",
    "\n",
    "    # Replacing the LMLs column with the round robin one\n",
    "    real_world_lmls$lml_real_world <- new_lmls_round_robin\n",
    "\n",
    "    # Eliminate column from dataframe\n",
    "    cross_lmls_prior$lml_real_world <- NULL\n",
    "\n",
    "    # Place this into initial dataframe\n",
    "    cross_lmls_prior <- merge( x = cross_lmls_prior,\n",
    "                               y = real_world_lmls, \n",
    "                               by = c('scenario', 'kernel'))\n",
    "\n",
    "    # Validation\n",
    "    print('All should be TRUE:')\n",
    "    # TODO: Print\n",
    "    print(((cross_lmls_prior %>% select(scenario, kernel, lml_real_world) %>% unique %>% arrange(scenario, kernel) %>% tail(11) %>% \n",
    "        select(lml_real_world)) == (cross_lmls_prior_initial  %>% select(scenario, kernel, lml_real_world) %>% unique %>% arrange(scenario, kernel) %>% head(11) %>% select(lml_real_world))) )\n",
    "\n",
    "    # Correlation calculations\n",
    "    cross_dcor1 <- ddply(cross_lmls_prior, ~scenario+pid, summarize, r=cor(rank(lml_participants), rank(lml_real_world)))\n",
    "    cross_dout <- ddply(cross_dcor1, ~scenario, summarize, m=cohensD(r))\n",
    "    cross_test_results_per_scenario <- tapply(cross_dcor1$r, cross_dcor1$scenario, t.test)\n",
    "\n",
    "    get_rho <- function(index){\n",
    "        c( cross_scenarios[index],\n",
    "           cross_scenarios_init[index],\n",
    "           (cross_test_results_per_scenario[[cross_scenarios_init[index]]][[5]] %>% round(2))[[1]] )\n",
    "    }\n",
    "\n",
    "    # Calculate the Rhos\n",
    "    rho_1 <- get_rho(1)\n",
    "    rho_2 <- get_rho(2)\n",
    "    rho_3 <- get_rho(3)\n",
    "    rho_4 <- get_rho(4)\n",
    "    rho_5 <- get_rho(5)\n",
    "    rho_6 <- get_rho(6)\n",
    "\n",
    "    # Bind them to the dataframe\n",
    "    partial_results <- t(data.frame(rho_1, rho_2, rho_3, rho_4, rho_5, rho_6))\n",
    "    colnames(partial_results) <- c('real_world_scenario', 'explained_by_participants_scenario', 'rho')\n",
    "    \n",
    "    results <- rbind(results, partial_results)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform value\n",
    "results_converted <- results\n",
    "results_converted$rho <- as.numeric(levels(results$rho))[results$rho]\n",
    "\n",
    "# Rho squared\n",
    "results_converted$rho_squared <- results_converted$rho * results_converted$rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation_rhos <- results_converted %>%\n",
    "                        filter(real_world_scenario != explained_by_participants_scenario) %>%\n",
    "                        group_by(real_world_scenario) %>%\n",
    "                        summarize(rho_squared_mean = mean(rho_squared))\n",
    "\n",
    "original_rhos <- results_converted %>%\n",
    "                        filter(real_world_scenario == explained_by_participants_scenario)\n",
    "\n",
    "final_results <- (merge( x = original_rhos,\n",
    "                        y = cross_validation_rhos,\n",
    "                        by = c('real_world_scenario'))) %>%\n",
    "                  mutate(difference = (rho_squared - rho_squared_mean) %>% round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>real_world_scenario</th><th scope=col>explained_by_participants_scenario</th><th scope=col>rho</th><th scope=col>rho_squared</th><th scope=col>rho_squared_mean</th><th scope=col>difference</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>FB Friends </td><td>FB Friends </td><td>0.62       </td><td>0.3844     </td><td>0.37206    </td><td> 0.01      </td></tr>\n",
       "\t<tr><td>Gym members</td><td>Gym members</td><td>0.16       </td><td>0.0256     </td><td>0.06252    </td><td>-0.04      </td></tr>\n",
       "\t<tr><td>Rain       </td><td>Rain       </td><td>0.58       </td><td>0.3364     </td><td>0.18094    </td><td> 0.16      </td></tr>\n",
       "\t<tr><td>Salary     </td><td>Salary     </td><td>0.61       </td><td>0.3721     </td><td>0.21670    </td><td> 0.16      </td></tr>\n",
       "\t<tr><td>Sales      </td><td>Sales      </td><td>0.48       </td><td>0.2304     </td><td>0.33004    </td><td>-0.10      </td></tr>\n",
       "\t<tr><td>Temperature</td><td>Temperature</td><td>0.61       </td><td>0.3721     </td><td>0.28840    </td><td> 0.08      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       " real\\_world\\_scenario & explained\\_by\\_participants\\_scenario & rho & rho\\_squared & rho\\_squared\\_mean & difference\\\\\n",
       "\\hline\n",
       "\t FB Friends  & FB Friends  & 0.62        & 0.3844      & 0.37206     &  0.01      \\\\\n",
       "\t Gym members & Gym members & 0.16        & 0.0256      & 0.06252     & -0.04      \\\\\n",
       "\t Rain        & Rain        & 0.58        & 0.3364      & 0.18094     &  0.16      \\\\\n",
       "\t Salary      & Salary      & 0.61        & 0.3721      & 0.21670     &  0.16      \\\\\n",
       "\t Sales       & Sales       & 0.48        & 0.2304      & 0.33004     & -0.10      \\\\\n",
       "\t Temperature & Temperature & 0.61        & 0.3721      & 0.28840     &  0.08      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "real_world_scenario | explained_by_participants_scenario | rho | rho_squared | rho_squared_mean | difference | \n",
       "|---|---|---|---|---|---|\n",
       "| FB Friends  | FB Friends  | 0.62        | 0.3844      | 0.37206     |  0.01       | \n",
       "| Gym members | Gym members | 0.16        | 0.0256      | 0.06252     | -0.04       | \n",
       "| Rain        | Rain        | 0.58        | 0.3364      | 0.18094     |  0.16       | \n",
       "| Salary      | Salary      | 0.61        | 0.3721      | 0.21670     |  0.16       | \n",
       "| Sales       | Sales       | 0.48        | 0.2304      | 0.33004     | -0.10       | \n",
       "| Temperature | Temperature | 0.61        | 0.3721      | 0.28840     |  0.08       | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  real_world_scenario explained_by_participants_scenario rho  rho_squared\n",
       "1 FB Friends          FB Friends                         0.62 0.3844     \n",
       "2 Gym members         Gym members                        0.16 0.0256     \n",
       "3 Rain                Rain                               0.58 0.3364     \n",
       "4 Salary              Salary                             0.61 0.3721     \n",
       "5 Sales               Sales                              0.48 0.2304     \n",
       "6 Temperature         Temperature                        0.61 0.3721     \n",
       "  rho_squared_mean difference\n",
       "1 0.37206           0.01     \n",
       "2 0.06252          -0.04     \n",
       "3 0.18094           0.16     \n",
       "4 0.21670           0.16     \n",
       "5 0.33004          -0.10     \n",
       "6 0.28840           0.08     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"positive in the temperature ($0.08$), rain ($0.16$), salary ($0.16$), and Facebook friends ($0.01$) scenarios.\"\n"
     ]
    }
   ],
   "source": [
    "print(paste0( \"positive in the temperature ($\", final_results[final_results$real_world_scenario=='Temperature', 'difference'], \n",
    "                            \"$), rain ($\", final_results[final_results$real_world_scenario=='Rain', 'difference'],\n",
    "                          \"$), salary ($\", final_results[final_results$real_world_scenario=='Salary', 'difference'], \n",
    "            \"$), and Facebook friends ($\", final_results[final_results$real_world_scenario=='FB Friends', 'difference'],  \n",
    "       \"$) scenarios.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior: Curves (participant's data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  scenario = col_character(),\n",
      "  day = col_integer(),\n",
      "  value = col_double()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mean_centering <- function(rwdata, dat, scenario) {\n",
    "    mean_rw <- rwdata %>% filter(scenario == !!scenario) %>% summarize(mv=mean(value))\n",
    "    \n",
    "    mean_dat <- dat %>% filter(scenario == !!scenario, condition == 'Prior') %>% summarize(mv=mean(value))    \n",
    "    \n",
    "    mean_dat$mv / mean_rw$mv\n",
    "}\n",
    "\n",
    "# Real world data\n",
    "rwdata <- read_csv('data/real-world/splines.csv')\n",
    "\n",
    "rwdata$condition <- 'Prior' # Add column\n",
    "rwdata$id <- 1 #Create a new ID column\n",
    "rwdata <- filter(rwdata, day >= 31) # Filter out the initial days\n",
    "rwdata <- filter(rwdata, day <= 365*4 - 31) # Filter out the final days\n",
    "\n",
    "# Order\n",
    "rwdata$condition <- factor( rwdata$condition, levels = condition_names)\n",
    "rwdata$scenario <- factor( rwdata$scenario, levels = readable_scenarios)\n",
    "\n",
    "# Scale the values\n",
    "#rwdata[rwdata$scenario == 'Rain', 'day'] <- rwdata[rwdata$scenario == 'Rain', 'day'] + (365/12) * 1.5 #Offset 1.5 months to the right\n",
    "\n",
    "# Mean centering\n",
    "for (s in readable_scenarios){\n",
    "    rwdata[rwdata$scenario == s, 'value'] <- rwdata[rwdata$scenario == s, 'value'] * mean_centering(rwdata, dat, s)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curves_plot <- function(scenario_name, ...) {\n",
    "    dat %>% \n",
    "        filter(scenario==scenario_name, condition=='Prior') %>% \n",
    "        plot_curves(rwdata %>% filter(scenario==scenario_name), scenario=scenario_name, ylab=scenario_name, ...)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_temp_curves   <- curves_plot('Temperature', hide_x=TRUE, hide_y=FALSE)\n",
    "p_rain_curves   <- curves_plot('Rain',        hide_x=TRUE, hide_y=FALSE)\n",
    "p_sales_curves  <- curves_plot('Sales',       hide_x=TRUE, hide_y=FALSE)\n",
    "p_gym_curves    <- curves_plot('Gym members', hide_x=TRUE, hide_y=FALSE)\n",
    "p_salary_curves <- curves_plot('Salary',      hide_x=TRUE, hide_y=FALSE)\n",
    "p_fb_curves     <- curves_plot('FB Friends',  hide_x=TRUE, hide_y=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if(FALSE){\n",
    "    # Save/show\n",
    "    pdf(\"Images/paper_images/grid_plot_prior_new.pdf\", width=6, height=10)\n",
    "    grid.arrange(p_temp_curves,   p_temp, \n",
    "                 p_rain_curves,   p_rain, \n",
    "                 p_sales_curves,  p_sales, \n",
    "                 p_gym_curves,    p_gym, \n",
    "                 p_salary_curves, p_salary, \n",
    "                 p_fb_curves,     p_fb, \n",
    "                 ncol=2)\n",
    "    dev.off()   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Posterior: Curves (participants' data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_curves_posterior <- function(plot_data, ylab='', scenario, hide_x=FALSE, hide_y=FALSE) {\n",
    "\n",
    "    # Min and max value of the data to be shown\n",
    "    range_y <- get_range(scenario)\n",
    "    limits_y <- c( min(range_y[1], min(plot_data$value)), max(range_y[2], max(plot_data$value)))\n",
    "    \n",
    "    # Mean trend\n",
    "    trend_1 <- plot_data %>% filter(condition=='Posterior-Positive') %>% group_by(day) %>% summarize(mean_y = mean(value))\n",
    "    trend_2 <- plot_data %>% filter(condition=='Posterior-Stable') %>%   group_by(day) %>% summarize(mean_y = mean(value))\n",
    "    trend_3 <- plot_data %>% filter(condition=='Posterior-Negative') %>% group_by(day) %>% summarize(mean_y = mean(value))\n",
    "    \n",
    "    # Resolution subsetting\n",
    "    resolution = 10 #smaller number is higher resolution\n",
    "    plot_data <- plot_data %>% filter((day - min(day)) %% resolution == 0)\n",
    "    trend_1 <- trend_1 %>% filter((day - min(day)) %% resolution == 0)\n",
    "    trend_2 <- trend_2 %>% filter((day - min(day)) %% resolution == 0)\n",
    "    trend_3 <- trend_3 %>% filter((day - min(day)) %% resolution == 0)\n",
    "    \n",
    "    # Plotting\n",
    "    plot <- plot_data %>%\n",
    "                ggplot(aes(x=day, y=value, group=id)) +\n",
    "                    # Curves:\n",
    "                    geom_line(data=plot_data %>% filter(condition=='Posterior-Positive'), col=\"steelblue\", alpha=0.1) +\n",
    "                    geom_line(data=plot_data %>% filter(condition=='Posterior-Stable'),   col=\"olivedrab\", alpha=0.1) +\n",
    "                    geom_line(data=plot_data %>% filter(condition=='Posterior-Negative'), col=\"firebrick\", alpha=0.1) +\n",
    "                    \n",
    "                    # Mean curves\n",
    "                    geom_line(data=trend_1, aes(x=day, y=mean_y, group=1), colour=\"blue\") +\n",
    "                    geom_line(data=trend_2, aes(x=day, y=mean_y, group=1), colour=\"darkgreen\") +\n",
    "                    geom_line(data=trend_3, aes(x=day, y=mean_y, group=1), colour=\"red\") +\n",
    "                    \n",
    "                    # Vertical line (end of evidence mark)\n",
    "                    geom_vline(aes(xintercept=365-31), colour='black') +\n",
    "    \n",
    "                    ggthemes::theme_few() +\n",
    "                    ylab(ylab) +\n",
    "                    scale_x_continuous(breaks = c(0, 365, 365*2, 365*3), labels=c('Y1', 'Y2', 'Y3', 'Y4')) +\n",
    "                    scale_y_continuous(breaks = seq(range_y[1], range_y[2], length.out=3), limits=limits_y) +\n",
    "                    theme(axis.text.x = element_text(angle = 90,  vjust = 0.5, hjust=0),\n",
    "                          axis.text.y = element_text(angle = 90,  vjust = 0.5, hjust=0.5),\n",
    "                          text = element_text(size=12, family=\"serif\"))\n",
    "\n",
    "    if(hide_x){\n",
    "        plot <- plot + theme(axis.title.x=element_blank())\n",
    "    }\n",
    "    if(hide_y){\n",
    "        plot <- plot + theme(axis.title.y=element_blank())\n",
    "    }\n",
    "    \n",
    "    return(plot)\n",
    "}\n",
    "    \n",
    "curves_plot_posterior <- function(scenario_name, ...) {\n",
    "    dat %>% \n",
    "        filter(scenario==scenario_name, condition!='Prior') %>% \n",
    "        plot_curves_posterior(scenario=scenario_name, ylab=scenario_name, ...)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "posterior_curves_temp <- curves_plot_posterior('Temperature', hide_x=TRUE, hide_y=FALSE)\n",
    "posterior_curves_rain <- curves_plot_posterior('Rain',        hide_x=TRUE, hide_y=FALSE)\n",
    "posterior_curves_sale <- curves_plot_posterior('Sales',       hide_x=TRUE, hide_y=FALSE)\n",
    "posterior_curves_gymm <- curves_plot_posterior('Gym members', hide_x=TRUE, hide_y=FALSE)\n",
    "posterior_curves_slry <- curves_plot_posterior('Salary',      hide_x=TRUE, hide_y=FALSE)\n",
    "posterior_curves_fbfr <- curves_plot_posterior('FB Friends',  hide_x=TRUE, hide_y=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior: Performance. Prediction against participant's results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing the posterior kernel composition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Returns the data (after double filtering)\n",
    "get_filtered_data <- function(src_lmls, src_dict) {\n",
    "    lmls_posterior <- read_csv(src_lmls)\n",
    "\n",
    "    \n",
    "    # To add the 'scenario' column\n",
    "    data_posterior <- read_csv(src_dict)\n",
    "\n",
    "\n",
    "    # Posterior \"dictionary\"\n",
    "    dict_posterior <- data_posterior %>%                        \n",
    "                            group_by(id, pid, scenario, condition) %>%\n",
    "                            summarize()\n",
    "\n",
    "    lmls_posterior <- merge(x = lmls_posterior, y = dict_posterior, by = c(\"id\", \"id\"), all.x = TRUE)\n",
    "\n",
    "    # Removing unusable data\n",
    "    lmls_posterior_f <- lmls_posterior %>%\n",
    "                        filter(kernel != 'l', kernel != 'p', kernel != 'r') %>%\n",
    "                        filter(second_exception == 'False' & lml != -999999999)\n",
    "\n",
    "    # Standard deviations calculation\n",
    "    sds <- lmls_posterior_f %>% \n",
    "                group_by(kernel, scenario) %>%\n",
    "                summarize(lo_bound = mean(lml) - 5*sd(lml), up_bound = mean(lml) + 5*sd(lml))\n",
    "\n",
    "    sds$ks <- paste0(sds$kernel, sds$scenario)\n",
    "\n",
    "    lmls_posterior_f$ks <- paste0(lmls_posterior_f$kernel, lmls_posterior_f$scenario)\n",
    "\n",
    "    sds$kernel <- NULL\n",
    "    sds$scenario <- NULL\n",
    "\n",
    "    lmls_posterior_f <- merge(x = lmls_posterior_f, y = sds, by = \"ks\", all.x = TRUE)\n",
    "\n",
    "    lmls_posterior_ff <- lmls_posterior_f %>%\n",
    "                filter(lml > lo_bound & lml < up_bound)\n",
    "    \n",
    "    return (lmls_posterior_ff)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  id = col_integer(),\n",
      "  kernel = col_character(),\n",
      "  lml = col_double(),\n",
      "  white_added = col_character(),\n",
      "  second_exception = col_character()\n",
      ")\n",
      "Warning message:\n",
      "\"Missing column names filled in: 'X1' [1]\"Parsed with column specification:\n",
      "cols(\n",
      "  X1 = col_integer(),\n",
      "  id = col_integer(),\n",
      "  pid = col_character(),\n",
      "  scenario = col_character(),\n",
      "  x = col_integer(),\n",
      "  y = col_double(),\n",
      "  condition = col_character()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lmls_posterior_ff <- get_filtered_data( \"output/minus-mean-treatment/results_posterior_lmls.csv\",\n",
    "                                        \"data/for_composititional_analysis_posterior.csv\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  pid = col_integer(),\n",
      "  composition = col_character(),\n",
      "  Xpredictions = col_double(),\n",
      "  predictions_mean = col_character(),\n",
      "  predictions_var = col_character()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Import the predictions\n",
    "predictions_csv <- read_csv('output/minus-mean-treatment/results_posterior_predictions.csv')\n",
    "\n",
    "predictions <- predictions_csv %>%\n",
    "                    mutate(value = as.numeric(substring(predictions_mean, 2, nchar(predictions_mean)-1))) %>%\n",
    "                    select(cid = pid, kernel = composition, day = Xpredictions, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"Missing column names filled in: 'X1' [1]\"Parsed with column specification:\n",
      "cols(\n",
      "  X1 = col_integer(),\n",
      "  id = col_integer(),\n",
      "  pid = col_character(),\n",
      "  scenario = col_character(),\n",
      "  x = col_integer(),\n",
      "  y = col_double(),\n",
      "  condition = col_character()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Add the subtracted mean of the 'evidence' data\n",
    "posterior_means <- read_csv(\"data/for_composititional_analysis_posterior.csv\") %>% #data_posterior\n",
    "                        filter(x <= 365-31) %>%\n",
    "                        group_by(id) %>%\n",
    "                        summarize(mean_cid = mean(y))\n",
    "\n",
    "predictions <- merge(x=predictions, y=posterior_means, by.x='cid', by.y='id', all.x=TRUE)\n",
    "\n",
    "predictions <- predictions %>% \n",
    "                    mutate(value = value + mean_cid) %>%\n",
    "                    select(-mean_cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "714"
      ],
      "text/latex": [
       "714"
      ],
      "text/markdown": [
       "714"
      ],
      "text/plain": [
       "[1] 714"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "9996"
      ],
      "text/latex": [
       "9996"
      ],
      "text/markdown": [
       "9996"
      ],
      "text/plain": [
       "[1] 9996"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions %>% select(cid) %>% unique %>% nrow\n",
    "\n",
    "predictions %>% select(cid, kernel) %>% unique %>% nrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merging and filtering the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sequence of days to analyze:\n",
    "sequence = seq(365-31 + 2, 1426, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inner join. \n",
    "# This is the predictions data merged with the best performing (and filtered) kernels in the posterior condition\n",
    "pred <- merge( \n",
    "            # Predictions (full-Bayesian):\n",
    "            x = predictions %>%\n",
    "                    filter(day %in% sequence),\n",
    "\n",
    "            # Kernels after the filters:\n",
    "            y = lmls_posterior_ff %>%\n",
    "                    select(cid=id, pid, scenario, kernel, lml),\n",
    "            \n",
    "            all.y = TRUE,\n",
    "            by = c('cid', 'kernel')\n",
    ")\n",
    "\n",
    "# Participants' data\n",
    "participants_data <- dat %>% \n",
    "                        filter(day > 365-31, #remove evidence\n",
    "                               condition != 'Prior', #only Posterior conditions\n",
    "                               day %in% sequence) %>%\n",
    "                        select(pid = id, day, value_participant=value, scenario, condition, noise)\n",
    "\n",
    "# Merge the predictions with the real participants' data\n",
    "all_pred_data <- merge(\n",
    "                # Predictions + Kernel posterior analysis:\n",
    "                x = pred,\n",
    "    \n",
    "                # Participant's data:\n",
    "                y = participants_data,\n",
    "    \n",
    "                by = c('pid', 'scenario', 'day')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "714"
      ],
      "text/latex": [
       "714"
      ],
      "text/markdown": [
       "714"
      ],
      "text/plain": [
       "[1] 714"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "7724"
      ],
      "text/latex": [
       "7724"
      ],
      "text/markdown": [
       "7724"
      ],
      "text/plain": [
       "[1] 7724"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_pred_data %>% select(cid) %>% unique %>% nrow\n",
    "\n",
    "all_pred_data %>% select(cid, kernel) %>% unique %>% nrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Calculating the deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalized root mean squared deviation\n",
    "calculate_nrmsd <- function(value_prediction, value_participant) {\n",
    "    return (sqrt(sum((value_prediction - value_participant)^2) / length(value_prediction)) / (max(value_participant) - min(value_participant)))\n",
    "}\n",
    "\n",
    "#Normalized root mean squared error (as per Mozer et al. (2008))\n",
    "calculate_nrmse <- function(value_model, value_human) {\n",
    "    return ( sqrt( sum((value_human - value_model)^2) / sum((value_human - mean(value_human))^2) ) )\n",
    "}\n",
    "\n",
    "calculate_mean_error <- function(value_model, value_human) {\n",
    "    return ( mean(abs(value_model - value_human)) )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_pred <- all_pred_data %>% \n",
    "                    mutate(kernel = readable_kernel(kernel)) %>%\n",
    "                    group_by(pid, scenario, kernel, lml) %>%\n",
    "                    summarize(error = calculate_nrmse(value, value_participant))\n",
    "                    #summarize(error = calculate_mean_error(value, value_participant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third grid plot. \n",
    "Identical to the posterior grid plot, but the right column is a scatterplot of prior likelihood vs posterior performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Raw LML in the fitting of the GPs onto the prior stage data\n",
    "scatterplot_data_prior <- lmls_prior_ff %>%\n",
    "                            select(pid, scenario, kernel, lml)\n",
    "\n",
    "# Raw Error in the posterior predictions\n",
    "scatterplot_data_posterior <- results_pred %>%\n",
    "                                select(pid, scenario, kernel, lml, error_posterior=error)\n",
    "\n",
    "scatterplot_data <- merge(\n",
    "                            x = scatterplot_data_prior,\n",
    "                            y = scatterplot_data_posterior,\n",
    "                            by = c('pid', 'scenario', 'kernel'),\n",
    "                            suffixes = c('_prior', '_posterior') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Charley Wu Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: 'MASS'\n",
      "\n",
      "The following object is masked from 'package:dplyr':\n",
      "\n",
      "    select\n",
      "\n",
      "Warning message:\n",
      "\"failed to assign RegisteredNativeSymbol for transpose to transpose since transpose is already defined in the 'spam' namespace\"Warning message:\n",
      "\"failed to assign RegisteredNativeSymbol for toeplitz to toeplitz since toeplitz is already defined in the 'spam' namespace\""
     ]
    }
   ],
   "source": [
    "library(MASS)\n",
    "\n",
    "plot_scenario_scatterplot_wu <- function(data_to_plot, scenario_name, y_max) {\n",
    "    \n",
    "    y_max = 11\n",
    "    \n",
    "    # Filter and normalize\n",
    "    aux <- data_to_plot %>% \n",
    "            filter(kernel != 'l', kernel != 'p', kernel != 'r') %>%\n",
    "            filter(scenario == scenario_name) %>%\n",
    "            group_by( pid, scenario ) %>%\n",
    "            mutate(lml_normalized = standardize_range_one(lml_prior),\n",
    "                   error_normalized = standardize_range_one(error_posterior), \n",
    "                   error_ranking = rank(error_posterior))\n",
    "\n",
    "    # Only analysis dataframe\n",
    "    cor1D <- data.frame(lambda1 = aux$lml_normalized, \n",
    "                        lambda2 = aux$error_ranking)\n",
    "    \n",
    "    # Correlation test\n",
    "    lambdaCor <- cor.test(cor1D$lambda1, cor1D$lambda2)\n",
    "\n",
    "    # Bivariate point density\n",
    "    cor1D$lambdadensity <- fields::interp.surface(MASS::kde2d(cor1D$lambda1, cor1D$lambda2), cor1D[,c(\"lambda1\", \"lambda2\")])\n",
    "    \n",
    "    # Plot\n",
    "    ggplot(cor1D, aes(lambda1, lambda2, fill=lambdadensity, alpha = standardize_range_one(1/lambdadensity))) +\n",
    "        geom_point(pch=21, size = 2.0, color='white')+\n",
    "        geom_smooth(method='lm', color='black', se=FALSE, linetype=2, fullrange=TRUE)+\n",
    "        scale_fill_gradient(low = \"#0091ff\", high = \"#f0650e\") +\n",
    "        scale_alpha(range = c(.4, 1)) + guides(alpha=\"none\", fill=\"none\") +\n",
    "        #expand_limits(x = 0, y = 0) +\n",
    "        #annotate(\"text\", x = 1, y = 6, label = \"r == 0.62 * ~~'p<.001'\", parse=TRUE, size=6) +\n",
    "    \n",
    "        coord_cartesian(ylim = c(0, y_max))  +\n",
    "        scale_x_continuous(breaks = seq(0, 1, length.out=3)) +\n",
    "        scale_y_continuous(breaks = seq(1, y_max, length.out=2)) +\n",
    "        \n",
    "        xlab('Likelihood in Prior') + \n",
    "        ylab('Error in Posterior') +\n",
    "    \n",
    "        ggthemes::theme_few() +\n",
    "        theme(text = element_text(size=10, family=\"serif\"),\n",
    "                     legend.position = \"none\")\n",
    "}\n",
    "\n",
    "scatter_temp_wu <- plot_scenario_scatterplot_wu(scatterplot_data, 'Temperature', y_max = 30)\n",
    "scatter_rain_wu <- plot_scenario_scatterplot_wu(scatterplot_data, 'Rain',        y_max = 30)\n",
    "scatter_sale_wu <- plot_scenario_scatterplot_wu(scatterplot_data, 'Sales',       y_max = 10)\n",
    "scatter_gymm_wu <- plot_scenario_scatterplot_wu(scatterplot_data, 'Gym members', y_max = 30)\n",
    "scatter_slry_wu <- plot_scenario_scatterplot_wu(scatterplot_data, 'Salary',      y_max = 30)\n",
    "scatter_fbfr_wu <- plot_scenario_scatterplot_wu(scatterplot_data, 'FB Friends',  y_max = 30)\n",
    "\n",
    "\n",
    "#scatter_temp_wu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if(FALSE){\n",
    "    pdf(\"Images/paper_images/grid_plot_posterior_wu_rank_abs.pdf\", width=6, height=10)\n",
    "    multiplot(  posterior_curves_temp,\n",
    "                posterior_curves_rain,\n",
    "                posterior_curves_sale,\n",
    "                posterior_curves_gymm,\n",
    "                posterior_curves_slry,\n",
    "                posterior_curves_fbfr,\n",
    "              \n",
    "                scatter_temp_wu,\n",
    "                scatter_rain_wu,\n",
    "                scatter_sale_wu,\n",
    "                scatter_gymm_wu,\n",
    "                scatter_slry_wu,\n",
    "                scatter_fbfr_wu,\n",
    "                \n",
    "                cols = 2)\n",
    "    dev.off()   \n",
    "}\n",
    "\n",
    "detach(package:MASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical tests for the Posterior condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  id = col_integer(),\n",
      "  kernel = col_character(),\n",
      "  lml = col_double(),\n",
      "  white_added = col_character(),\n",
      "  second_exception = col_character()\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "1.66"
      ],
      "text/latex": [
       "1.66"
      ],
      "text/markdown": [
       "1.66"
      ],
      "text/plain": [
       "[1] 1.66"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Percentage of removed GPs in the Prior condition:\n",
    "((1 -\n",
    "lmls_posterior_ff %>%\n",
    "    filter(kernel != 'l', kernel != 'p', kernel != 'r') %>%\n",
    "    nrow / \n",
    "read_csv(\"output/minus-mean-treatment/results_posterior_lmls.csv\") %>%\n",
    "    filter(kernel != 'l', kernel != 'p', kernel != 'r') %>%\n",
    "    nrow) * 100) %>%\n",
    "round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear model in error ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_test_error <- scatterplot_data %>% \n",
    "            filter(kernel != 'l', kernel != 'p', kernel != 'r') %>%\n",
    "            group_by( pid, scenario ) %>%\n",
    "            mutate(lml_prior_standardized = standardize_range_one(lml_prior), # x\n",
    "                   error_ranking = rank(error_posterior))                     # y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm_by_scenario <- lapply( split(to_test_error, to_test_error$scenario), \n",
    "                          function(data) lm(error_ranking ~ lml_prior_standardized, data))\n",
    "                              \n",
    "lm_overall <- lm(error_ranking ~ lml_prior_standardized, data = to_test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eric's cool correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_test_error <- scatterplot_data %>% \n",
    "            filter(kernel != 'l', kernel != 'p', kernel != 'r') %>%\n",
    "            group_by( pid, scenario ) %>%\n",
    "            mutate(lml_prior_standardized = standardize_range_one(lml_prior))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Per scenario\"\n",
      "[1] \"Overall\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\tOne Sample t-test\n",
       "\n",
       "data:  dcor2$r\n",
       "t = -9.3949, df = 118, p-value = 5.429e-16\n",
       "alternative hypothesis: true mean is not equal to 0\n",
       "95 percent confidence interval:\n",
       " -0.15066086 -0.09820455\n",
       "sample estimates:\n",
       " mean of x \n",
       "-0.1244327 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.86"
      ],
      "text/latex": [
       "0.86"
      ],
      "text/markdown": [
       "0.86"
      ],
      "text/plain": [
       "[1] 0.86"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Per scenario')\n",
    "dcor1 <- ddply(to_test_error, ~scenario+pid, summarize, r = cor(x = lml_prior_standardized, rank(error_posterior)))\n",
    "\n",
    "dout <- ddply(dcor1, ~scenario, summarize, m=cohensD(r))\n",
    "test_results_per_scenario <- tapply(dcor1$r, dcor1$scenario, t.test)\n",
    "\n",
    "print('Overall')\n",
    "dcor2 <- ddply(to_test_error, ~pid, summarize, r = cor(x = lml_prior_standardized, rank(error_posterior)))\n",
    "\n",
    "t.test(dcor2$r)\n",
    "cohensD(dcor2$r) %>% round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \", $\\rho=-0.23$ ($t(118)=-6.77, p<0.001, d=0.62$) for the temperature data, $\\rho=-0.25$ ($t(118)=-8.54, p<0.001, d=0.78$) for the rain data, $\\rho=-0.1$ ($t(118)=-3.37, p0.00102089937190916, d=0.31$) for the sales data, $\\rho=-0.16$ ($t(118)=-4.6, p<0.001, d=0.42$) for the gym membership data, $\\rho=-0.01$ ($t(118)=-0.24, p0.814323148477005, d=0.02$) for the salary data, $\\rho=-0.14$ ($t(118)=-4.35, p<0.001, d=0.4$) for the Facebook friends data\"\n"
     ]
    }
   ],
   "source": [
    "paste0(  print_test_results('Temperature', 'temperature'),\n",
    "        print_test_results('Rain', 'rain'),\n",
    "        print_test_results('Sales', 'sales'),\n",
    "        print_test_results('Gym members', 'gym membership'),\n",
    "        print_test_results('Salary', 'salary'),\n",
    "        print_test_results('FB Friends', 'Facebook friends')) %>% print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend damping\n",
    "### Goal: Proportion of damped predictions. Participants vs GP Predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Calculate underlying trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df <- dat %>%\n",
    "        group_by(condition, scenario, day) %>%\n",
    "        summarize\n",
    "\n",
    "df$slope_scale <- mapvalues(df$condition,\n",
    "                              from = c(\"Prior\", \"Posterior-Positive\", \"Posterior-Stable\", \"Posterior-Negative\"),\n",
    "                              to   = c(0, 1, 0, -1))\n",
    "\n",
    "df$range <- mapvalues(df$scenario,\n",
    "                              from = c(\"Temperature\", \"Rain\", \"Sales\", \"Gym members\", \"Salary\", \"FB Friends\"),\n",
    "                              to   = c( 40--10,        100-0,  5000-0,  50-0,          50-0,     1000-0))\n",
    "\n",
    "df$y_intercept <- mapvalues(df$scenario,\n",
    "                              from = c(\"Temperature\", \"Rain\", \"Sales\", \"Gym members\", \"Salary\", \"FB Friends\"),\n",
    "                              to   = c( 15,            30,     2500,    25,            20,       500))\n",
    "\n",
    "\n",
    "# Transformations to numbers\n",
    "df$slope_scale <- as.numeric(levels(df$slope_scale))[df$slope_scale]\n",
    "df$range <- as.numeric(levels(df$range))[df$range]\n",
    "df$y_intercept <- as.numeric(levels(df$y_intercept))[df$y_intercept]\n",
    "\n",
    "# Calculations\n",
    "df$last_point <- df$y_intercept + 0.05 * df$range * df$slope_scale * 4 \n",
    "\n",
    "df$slope <- (df$last_point - df$y_intercept) / ((365-31)-1)\n",
    "\n",
    "df$underlying_trend <- ((df$day-1) * df$slope + df$y_intercept)\n",
    "\n",
    "# Subtract the mean of each underlying trend\n",
    "#df <- df %>% \n",
    "#        group_by(condition, scenario) %>%\n",
    "#        mutate(underlying_trend = underlying_trend - mean(underlying_trend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>pid</th><th scope=col>scenario</th><th scope=col>day</th><th scope=col>cid</th><th scope=col>kernel</th><th scope=col>value</th><th scope=col>lml</th><th scope=col>value_participant</th><th scope=col>condition</th><th scope=col>noise</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>a001              </td><td>FB Friends        </td><td>1001              </td><td>6                 </td><td>l+r+p             </td><td>156.2030          </td><td>-334.52795        </td><td>255.7962          </td><td>Posterior-Negative</td><td>3                 </td></tr>\n",
       "\t<tr><td>a001              </td><td>FB Friends        </td><td>1001              </td><td>6                 </td><td>l+r               </td><td>112.2065          </td><td> -72.20523        </td><td>255.7962          </td><td>Posterior-Negative</td><td>3                 </td></tr>\n",
       "\t<tr><td>a001              </td><td>FB Friends        </td><td>1001              </td><td>6                 </td><td>p*r               </td><td>382.4196          </td><td>-323.93799        </td><td>255.7962          </td><td>Posterior-Negative</td><td>3                 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       " pid & scenario & day & cid & kernel & value & lml & value\\_participant & condition & noise\\\\\n",
       "\\hline\n",
       "\t a001               & FB Friends         & 1001               & 6                  & l+r+p              & 156.2030           & -334.52795         & 255.7962           & Posterior-Negative & 3                 \\\\\n",
       "\t a001               & FB Friends         & 1001               & 6                  & l+r                & 112.2065           &  -72.20523         & 255.7962           & Posterior-Negative & 3                 \\\\\n",
       "\t a001               & FB Friends         & 1001               & 6                  & p*r                & 382.4196           & -323.93799         & 255.7962           & Posterior-Negative & 3                 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "pid | scenario | day | cid | kernel | value | lml | value_participant | condition | noise | \n",
       "|---|---|---|\n",
       "| a001               | FB Friends         | 1001               | 6                  | l+r+p              | 156.2030           | -334.52795         | 255.7962           | Posterior-Negative | 3                  | \n",
       "| a001               | FB Friends         | 1001               | 6                  | l+r                | 112.2065           |  -72.20523         | 255.7962           | Posterior-Negative | 3                  | \n",
       "| a001               | FB Friends         | 1001               | 6                  | p*r                | 382.4196           | -323.93799         | 255.7962           | Posterior-Negative | 3                  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  pid  scenario   day  cid kernel value    lml        value_participant\n",
       "1 a001 FB Friends 1001 6   l+r+p  156.2030 -334.52795 255.7962         \n",
       "2 a001 FB Friends 1001 6   l+r    112.2065  -72.20523 255.7962         \n",
       "3 a001 FB Friends 1001 6   p*r    382.4196 -323.93799 255.7962         \n",
       "  condition          noise\n",
       "1 Posterior-Negative 3    \n",
       "2 Posterior-Negative 3    \n",
       "3 Posterior-Negative 3    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>condition</th><th scope=col>scenario</th><th scope=col>day</th><th scope=col>slope_scale</th><th scope=col>range</th><th scope=col>y_intercept</th><th scope=col>last_point</th><th scope=col>slope</th><th scope=col>underlying_trend</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Prior      </td><td>Temperature</td><td>31         </td><td>0          </td><td>50         </td><td>15         </td><td>15         </td><td>0          </td><td>15         </td></tr>\n",
       "\t<tr><td>Prior      </td><td>Temperature</td><td>32         </td><td>0          </td><td>50         </td><td>15         </td><td>15         </td><td>0          </td><td>15         </td></tr>\n",
       "\t<tr><td>Prior      </td><td>Temperature</td><td>33         </td><td>0          </td><td>50         </td><td>15         </td><td>15         </td><td>0          </td><td>15         </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllll}\n",
       " condition & scenario & day & slope\\_scale & range & y\\_intercept & last\\_point & slope & underlying\\_trend\\\\\n",
       "\\hline\n",
       "\t Prior       & Temperature & 31          & 0           & 50          & 15          & 15          & 0           & 15         \\\\\n",
       "\t Prior       & Temperature & 32          & 0           & 50          & 15          & 15          & 0           & 15         \\\\\n",
       "\t Prior       & Temperature & 33          & 0           & 50          & 15          & 15          & 0           & 15         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "condition | scenario | day | slope_scale | range | y_intercept | last_point | slope | underlying_trend | \n",
       "|---|---|---|\n",
       "| Prior       | Temperature | 31          | 0           | 50          | 15          | 15          | 0           | 15          | \n",
       "| Prior       | Temperature | 32          | 0           | 50          | 15          | 15          | 0           | 15          | \n",
       "| Prior       | Temperature | 33          | 0           | 50          | 15          | 15          | 0           | 15          | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  condition scenario    day slope_scale range y_intercept last_point slope\n",
       "1 Prior     Temperature 31  0           50    15          15         0    \n",
       "2 Prior     Temperature 32  0           50    15          15         0    \n",
       "3 Prior     Temperature 33  0           50    15          15         0    \n",
       "  underlying_trend\n",
       "1 15              \n",
       "2 15              \n",
       "3 15              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>pid</th><th scope=col>scenario</th><th scope=col>kernel</th><th scope=col>lml</th><th scope=col>error</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>a001      </td><td>FB Friends</td><td>l+p       </td><td>-298.9917 </td><td>3.763067  </td></tr>\n",
       "\t<tr><td>a001      </td><td>FB Friends</td><td>l+p+r     </td><td>-334.5280 </td><td>4.830658  </td></tr>\n",
       "\t<tr><td>a001      </td><td>FB Friends</td><td>l+p×r     </td><td>-287.4414 </td><td>2.744849  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " pid & scenario & kernel & lml & error\\\\\n",
       "\\hline\n",
       "\t a001       & FB Friends & l+p        & -298.9917  & 3.763067  \\\\\n",
       "\t a001       & FB Friends & l+p+r      & -334.5280  & 4.830658  \\\\\n",
       "\t a001       & FB Friends & l+p×r      & -287.4414  & 2.744849  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "pid | scenario | kernel | lml | error | \n",
       "|---|---|---|\n",
       "| a001       | FB Friends | l+p        | -298.9917  | 3.763067   | \n",
       "| a001       | FB Friends | l+p+r      | -334.5280  | 4.830658   | \n",
       "| a001       | FB Friends | l+p×r      | -287.4414  | 2.744849   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  pid  scenario   kernel lml       error   \n",
       "1 a001 FB Friends l+p    -298.9917 3.763067\n",
       "2 a001 FB Friends l+p+r  -334.5280 4.830658\n",
       "3 a001 FB Friends l+p×r  -287.4414 2.744849"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1691556"
      ],
      "text/latex": [
       "1691556"
      ],
      "text/markdown": [
       "1691556"
      ],
      "text/plain": [
       "[1] 1691556"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "33576"
      ],
      "text/latex": [
       "33576"
      ],
      "text/markdown": [
       "33576"
      ],
      "text/plain": [
       "[1] 33576"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Watching the columns\n",
    "all_pred_data %>% head(3) # This has the day to day data\n",
    "df %>% head(3)            # This has the underlying trend\n",
    "results_pred %>% head(3)  # This has the error (against prediction)\n",
    "\n",
    "all_pred_data %>% nrow\n",
    "df %>% nrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_merge_1 <- all_pred_data %>% \n",
    "                    select(cid, pid, condition, scenario, kernel, day, value_model = value, value_participant)\n",
    "\n",
    "to_merge_1$kernel <- readable_kernel(to_merge_1$kernel) # Readability of the kernel\n",
    "\n",
    "to_merge_2 <- results_pred %>%\n",
    "                    group_by(pid, scenario) %>% # PER PARTICIPANT AND SCENARIO\n",
    "                    mutate(lml_prior = lml, error_posterior=error) %>%\n",
    "                    \n",
    "                    mutate(best = kernel[which.max(lml_prior)]) %>% # <-- VERY IMPORTANT\n",
    "                    #mutate(best = kernel[which.min(error_posterior)]) %>% # <-- VERY IMPORTANT\n",
    "\n",
    "                    select(pid, scenario, kernel, lml_prior, error_posterior, best)\n",
    "\n",
    "first_merge <- merge( x = to_merge_1,\n",
    "                      y = to_merge_2,\n",
    "                      by = c('pid', 'scenario', 'kernel'),\n",
    "                      all.y = TRUE)\n",
    "\n",
    "data_with_trend <- merge( x = first_merge,\n",
    "                          y = df %>% select(condition, scenario, day, underlying_trend),\n",
    "                          by = c('condition', 'scenario', 'day'),\n",
    "                          all.x = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter out the other scenarios. Leave only SALES/GYM MEMBERS\n",
    "data_with_trend_f <- data_with_trend %>%\n",
    "                                filter(condition == 'Posterior-Positive' | condition == 'Posterior-Negative') %>%\n",
    "                                filter(scenario == 'Sales') %>% # CHOSEN SCENARIO   <-------------  IMPORTANT\n",
    "                                #filter(scenario == 'Gym members') %>%\n",
    "                                filter(kernel == best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Which values are \"damped\"?\n",
    "add_damped_column <- function(dataset, condition, column_name, new_column_name) {\n",
    "    \n",
    "    if(condition == 'Posterior-Negative') {\n",
    "        damped_column <- dataset[dataset$condition==condition, column_name] > dataset[dataset$condition==condition, 'underlying_trend'] \n",
    "    }else if(condition == 'Posterior-Positive') {\n",
    "        damped_column <- dataset[dataset$condition==condition, column_name] < dataset[dataset$condition==condition, 'underlying_trend'] \n",
    "    }\n",
    "    \n",
    "    dataset[dataset$condition == condition, new_column_name] <- damped_column\n",
    "    \n",
    "    return(dataset)\n",
    "}\n",
    " \n",
    "# Calculate the 'damped' boolean\n",
    "data_with_trend_ff <- add_damped_column(data_with_trend_f, 'Posterior-Negative', 'value_participant', new_column_name='damped_participant')\n",
    "data_with_trend_ff <- add_damped_column(data_with_trend_ff, 'Posterior-Positive', 'value_participant', new_column_name='damped_participant')\n",
    "    \n",
    "data_with_trend_ff <- add_damped_column(data_with_trend_ff, 'Posterior-Negative', 'value_model', new_column_name='damped_model')\n",
    "data_with_trend_ff <- add_damped_column(data_with_trend_ff, 'Posterior-Positive', 'value_model', new_column_name='damped_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Plot: Proportion of trend damping [not used]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 1e3\n",
    "\n",
    "damped_proportion_participants <- data_with_trend_ff %>%\n",
    "                                        group_by(condition, day) %>%\n",
    "                                        summarize(damped_proportion = mean(damped_participant),\n",
    "                                                  lo_ci = bp2(damped_participant, n=n)[[2]],\n",
    "                                                  hi_ci = bp2(damped_participant, n=n)[[3]])\n",
    "\n",
    "damped_proportion_gps <- data_with_trend_ff %>%\n",
    "                                        group_by(condition, day) %>%\n",
    "                                        summarize(damped_proportion = mean(damped_model),\n",
    "                                                  lo_ci = bp2(damped_model, n=n)[[2]],\n",
    "                                                  hi_ci = bp2(damped_model, n=n)[[3]])\n",
    "\n",
    "rm(n)\n",
    "\n",
    "# Merge the data into one dataframe\n",
    "damped_proportion_participants$type <- 'Participants'\n",
    "damped_proportion_gps$type <- 'Models'\n",
    "\n",
    "damped_proportion_1 <- rbind(damped_proportion_participants, damped_proportion_gps)\n",
    "\n",
    "damped_proportion_1$type <- factor(damped_proportion_1$type, levels=c('Participants', 'Models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "damped_plot <- function(damped_proportion) {\n",
    "\n",
    "    damped_proportion %>%\n",
    "    ggplot(aes(x=day, y=damped_proportion, group=condition, colour=condition)) +\n",
    "            geom_line(size=1) +\n",
    "            geom_ribbon(aes(ymin=lo_ci, ymax=hi_ci), alpha=0.2) +\n",
    "            ylab(\"Damped proportion in the Sales scenario\") +\n",
    "            scale_x_continuous( lim = c(min(damped_proportion$day), 365*2), \n",
    "                                breaks=c(0, 365, 365*2, 365*3), \n",
    "                                labels=c('Y1', 'Y2', 'Y3', 'Y4') ) +\n",
    "            theme_bw() + \n",
    "            #ggthemes::theme_few() + \n",
    "            theme( text = element_text(size=12, family=\"serif\"),\n",
    "                   legend.position = \"bottom\",\n",
    "                   axis.title.x=element_blank(),\n",
    "                   legend.title = element_blank() ) +\n",
    "            ggthemes::scale_color_solarized() +\n",
    "            facet_grid(type ~ .)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if(TRUE){ #save_damped_proportion_pdf\n",
    "    pdf(\"Images/paper_images/damped_proportion.pdf\", width=6, height=4)\n",
    "    print(damped_plot(damped_proportion_1))\n",
    "    dev.off()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Plot: Proportion of trend damping (fixed damping from first damp onwards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculating the first day of damping (participant)\n",
    "first_day_damped_participant <- data_with_trend_ff %>% \n",
    "            group_by(pid, condition, scenario) %>%\n",
    "            filter(damped_participant == TRUE) %>%\n",
    "            #filter(day > 365) %>%  # <--- IMPORTANT\n",
    "            summarize(first_day_damped_participant = min(day))\n",
    "\n",
    "# Calculating the first day of damping (model)\n",
    "first_day_damped_model <- data_with_trend_ff %>% \n",
    "            group_by(pid, condition, scenario) %>%\n",
    "            filter(damped_model == TRUE) %>%\n",
    "            #filter(day > 365) %>%  # <--- IMPORTANT\n",
    "            summarize(first_day_damped_model = min(day))\n",
    "\n",
    "# Adding this as a column named \n",
    "data_with_trend_ff_2 <- merge( x = data_with_trend_ff,\n",
    "                               y = first_day_damped_participant,\n",
    "                               by = c('pid', 'condition', 'scenario'),\n",
    "                               all.x = TRUE )\n",
    "\n",
    "data_with_trend_ff_2 <- merge( x = data_with_trend_ff_2,\n",
    "                               y = first_day_damped_model,\n",
    "                               by = c('pid', 'condition', 'scenario'),\n",
    "                               all.x = TRUE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_with_trend_ff_2 <- data_with_trend_ff_2 %>% \n",
    "        mutate( damped_participant = (day > first_day_damped_participant) | damped_participant ) %>%\n",
    "        mutate( damped_model = (day > first_day_damped_model) | damped_model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"Removed 280 rows containing missing values (geom_path).\""
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>png:</strong> 2"
      ],
      "text/latex": [
       "\\textbf{png:} 2"
      ],
      "text/markdown": [
       "**png:** 2"
      ],
      "text/plain": [
       "png \n",
       "  2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 1e4\n",
    "\n",
    "damped_proportion_participants <- data_with_trend_ff_2 %>%\n",
    "                                        group_by(condition, day) %>%\n",
    "                                        summarize(damped_proportion = mean(damped_participant),\n",
    "                                                  lo_ci = bp2(damped_participant, n=n)[[2]],\n",
    "                                                  hi_ci = bp2(damped_participant, n=n)[[3]])\n",
    "\n",
    "damped_proportion_gps <- data_with_trend_ff_2 %>%\n",
    "                                        group_by(condition, day) %>%\n",
    "                                        summarize(damped_proportion = mean(damped_model),\n",
    "                                                  lo_ci = bp2(damped_model, n=n)[[2]],\n",
    "                                                  hi_ci = bp2(damped_model, n=n)[[3]])\n",
    "\n",
    "rm(n)\n",
    "\n",
    "# Merge the data into one dataframe\n",
    "damped_proportion_participants$type <- 'Participants'\n",
    "damped_proportion_gps$type <- 'Models'\n",
    "\n",
    "damped_proportion_2 <- rbind(damped_proportion_participants, damped_proportion_gps)\n",
    "\n",
    "damped_proportion_2$type <- factor(damped_proportion_2$type, levels=c('Participants', 'Models'))\n",
    "\n",
    "if(TRUE){ #save_damped_proportion_pdf\n",
    "    pdf(\"Images/paper_images/damped_proportion_fixed_init.pdf\", width=6, height=4)\n",
    "    print(damped_plot(damped_proportion_2))\n",
    "    dev.off()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Plot: Best performing kernel (in Prior condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAOVBMVEUAAAAzMzNNTU1ZWVlo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\nBOZ/TTy7Cd5SqgoAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "number_rows <- data_with_trend_ff %>% \n",
    "                    select(pid, kernel) %>% \n",
    "                    unique %>%\n",
    "                    nrow\n",
    "\n",
    "# Ordering the kernels\n",
    "data_with_trend_ff_ordered <- data_with_trend_ff\n",
    "data_with_trend_ff_ordered$kernel <- factor(data_with_trend_ff_ordered$kernel, levels = kernels_2)\n",
    "\n",
    "# Producing the proportions\n",
    "data_with_trend_ff_ordered %>% \n",
    "    select(pid, kernel) %>% \n",
    "    unique %>%\n",
    "    group_by(kernel) %>%\n",
    "    summarize(value = length(kernel) / number_rows) %>%\n",
    "\n",
    "# Making the plot\n",
    "    ggplot(aes(x=kernel, y=value)) + \n",
    "    geom_bar(stat='identity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trend damping statistical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### i) Proportion of trend damping along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Posterior-Positive\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = damped_proportion_participants ~ damped_proportion_models, \n",
       "    data = damped_to_test %>% filter(condition == c))\n",
       "\n",
       "Residuals:\n",
       "      Min        1Q    Median        3Q       Max \n",
       "-0.111649 -0.006386  0.007022  0.007022  0.084469 \n",
       "\n",
       "Coefficients:\n",
       "                         Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)               -0.5238     0.1010  -5.185  1.7e-06 ***\n",
       "damped_proportion_models   1.4905     0.1031  14.462  < 2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.03208 on 77 degrees of freedom\n",
       "Multiple R-squared:  0.7309,\tAdjusted R-squared:  0.7274 \n",
       "F-statistic: 209.2 on 1 and 77 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Posterior-Negative\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = damped_proportion_participants ~ damped_proportion_models, \n",
       "    data = damped_to_test %>% filter(condition == c))\n",
       "\n",
       "Residuals:\n",
       "     Min       1Q   Median       3Q      Max \n",
       "-0.04737 -0.03013  0.02701  0.02701  0.11225 \n",
       "\n",
       "Coefficients:\n",
       "                         Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)               -0.4237     0.1744  -2.429   0.0175 *  \n",
       "damped_proportion_models   1.3967     0.1760   7.935 1.35e-11 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.0339 on 77 degrees of freedom\n",
       "Multiple R-squared:  0.4499,\tAdjusted R-squared:  0.4427 \n",
       "F-statistic: 62.97 on 1 and 77 DF,  p-value: 1.355e-11\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "damped_to_test <- merge(\n",
    "        x = damped_proportion_2 %>% filter(type == 'Participants') %>% select(condition, day, damped_proportion),\n",
    "\n",
    "        y = damped_proportion_2 %>% filter(type == 'Models') %>% select(condition, day, damped_proportion),\n",
    "\n",
    "        by = c('condition', 'day'),\n",
    "        suffixes = c('_participants', '_models')) %>%\n",
    "        mutate(subtraction = damped_proportion_participants - damped_proportion_models) %>%\n",
    "        filter(day <= 365 * 2)\n",
    "\n",
    "c = 'Posterior-Positive'\n",
    "print(c)\n",
    "fit <- lm( damped_proportion_participants ~ damped_proportion_models, \n",
    "            data = damped_to_test %>% filter(condition == c))\n",
    "summary(fit)\n",
    "\n",
    "c = 'Posterior-Negative'\n",
    "print(c)\n",
    "fit <- lm( damped_proportion_participants ~ damped_proportion_models, \n",
    "            data = damped_to_test %>% filter(condition == c))\n",
    "summary(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ii) First damped point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Posterior-Positive\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = min_day_participants ~ min_day_models, data = first_point_damped %>% \n",
       "    filter(condition == condition_name))\n",
       "\n",
       "Residuals:\n",
       "   Min     1Q Median     3Q    Max \n",
       "-64.96 -19.86 -19.86 -19.86 310.14 \n",
       "\n",
       "Coefficients:\n",
       "               Estimate Std. Error t value Pr(>|t|)  \n",
       "(Intercept)    135.1419   131.3404   1.029   0.3104  \n",
       "min_day_models   0.6569     0.3806   1.726   0.0929 .\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 64.78 on 36 degrees of freedom\n",
       "Multiple R-squared:  0.07644,\tAdjusted R-squared:  0.05079 \n",
       "F-statistic:  2.98 on 1 and 36 DF,  p-value: 0.09289\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Posterior-Negative\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = min_day_participants ~ min_day_models, data = first_point_damped %>% \n",
       "    filter(condition == condition_name))\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-24.952  -7.146  -7.146  -7.146 149.401 \n",
       "\n",
       "Coefficients:\n",
       "                Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)    -444.8822   110.4283  -4.029  0.00031 ***\n",
       "min_day_models    2.3453     0.3247   7.223 2.78e-08 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 30.66 on 33 degrees of freedom\n",
       "Multiple R-squared:  0.6125,\tAdjusted R-squared:  0.6008 \n",
       "F-statistic: 52.17 on 1 and 33 DF,  p-value: 2.779e-08\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_point_damped <- merge(\n",
    "    x = data_with_trend_ff %>% \n",
    "            group_by(pid, condition, scenario) %>%\n",
    "            filter(damped_participant) %>%\n",
    "            #filter(day > 365) %>% # <---- VERY IMPORTANT\n",
    "            summarize(min_day = min(day)),\n",
    "    \n",
    "    y = data_with_trend_ff %>% \n",
    "            group_by(pid, condition, scenario) %>%\n",
    "            filter(damped_model) %>%\n",
    "            #filter(day > 365) %>% # <---- VERY IMPORTANT\n",
    "            summarize(min_day = min(day)),\n",
    "    \n",
    "    by = c('pid', 'condition', 'scenario'),\n",
    "\n",
    "    suffixes = c('_participants', '_models')) %>%\n",
    "\n",
    "    mutate(subtraction = min_day_participants - min_day_models)# %>% filter(min_day_participants != 336)\n",
    "\n",
    "fit_model_aux <- function(condition_name){\n",
    "    print(condition_name)\n",
    "    fit <- lm(min_day_participants ~ min_day_models, \n",
    "              data = first_point_damped %>% filter(condition == condition_name))\n",
    "    summary(fit)\n",
    "}\n",
    "\n",
    "fit_model_aux(\"Posterior-Positive\")\n",
    "fit_model_aux(\"Posterior-Negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iii) Damped proportion per participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Posterior-Positive\"\n",
      "\n",
      "Call:\n",
      "lm(formula = damped_mean_participant ~ damped_mean_model, data = damped_mean_per_pid %>% \n",
      "    filter(condition == condition_name))\n",
      "\n",
      "Residuals:\n",
      "     Min       1Q   Median       3Q      Max \n",
      "-0.39823 -0.04075  0.06956  0.06956  0.13070 \n",
      "\n",
      "Coefficients:\n",
      "                  Estimate Std. Error t value Pr(>|t|)    \n",
      "(Intercept)         0.6830     0.1267   5.389  4.9e-05 ***\n",
      "damped_mean_model   0.2475     0.1347   1.837   0.0837 .  \n",
      "---\n",
      "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
      "\n",
      "Residual standard error: 0.1268 on 17 degrees of freedom\n",
      "Multiple R-squared:  0.1657,\tAdjusted R-squared:  0.1166 \n",
      "F-statistic: 3.376 on 1 and 17 DF,  p-value: 0.08372\n",
      "\n",
      "[1] \"Posterior-Negative\"\n",
      "\n",
      "Call:\n",
      "lm(formula = damped_mean_participant ~ damped_mean_model, data = damped_mean_per_pid %>% \n",
      "    filter(condition == condition_name))\n",
      "\n",
      "Residuals:\n",
      "       1        2        3        4        5        6 \n",
      " 0.05327 -0.00444 -0.00444 -0.00444 -0.00444 -0.03552 \n",
      "\n",
      "Coefficients:\n",
      "                  Estimate Std. Error t value Pr(>|t|)  \n",
      "(Intercept)        -2.4484     0.9154  -2.675   0.0555 .\n",
      "damped_mean_model   3.4528     0.9243   3.735   0.0202 *\n",
      "---\n",
      "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
      "\n",
      "Residual standard error: 0.03232 on 4 degrees of freedom\n",
      "Multiple R-squared:  0.7772,\tAdjusted R-squared:  0.7215 \n",
      "F-statistic: 13.95 on 1 and 4 DF,  p-value: 0.0202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "up_bound_day <- 365*2 + 30\n",
    "\n",
    "damped_mean_per_pid <- data_with_trend_ff %>% \n",
    "                            group_by(pid, condition, scenario) %>%\n",
    "                            filter(day < up_bound_day) %>%\n",
    "                            summarize(damped_mean_participant = mean(damped_participant),\n",
    "                                      damped_mean_model = mean(damped_model))\n",
    "\n",
    "# Filter out those participants that were fully damped all along\n",
    "damped_mean_per_pid_f <- damped_mean_per_pid %>% filter(damped_mean_participant < 1)\n",
    "\n",
    "# Can the MODEL predict the PARTICIPANT?\n",
    "fit_model_aux <- function(condition_name){\n",
    "    print(condition_name)\n",
    "    fit <- lm(damped_mean_participant ~ damped_mean_model,\n",
    "              data = damped_mean_per_pid %>% filter(condition == condition_name))\n",
    "    summary(fit)   \n",
    "}\n",
    "\n",
    "print(fit_model_aux(condition_name = 'Posterior-Positive'))\n",
    "print(fit_model_aux(condition_name = 'Posterior-Negative'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"should be zero:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Should be zero because every curve and day combination should only have 1 datapoint\n",
    "print('should be zero:')\n",
    "\n",
    "data_with_trend %>% \n",
    "    group_by(cid, day) %>%\n",
    "    filter(length(day) != 1) %>% nrow\n",
    "\n",
    "data_with_trend %>% \n",
    "    group_by(cid, day, kernel) %>%\n",
    "    filter(length(kernel) != 1) %>% nrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior analysis, proportion of match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Should be TRUE:\"\n",
      "[1] TRUE\n"
     ]
    }
   ],
   "source": [
    "error_posterior_incomplete <- results_pred %>% \n",
    "                                    mutate(true_lml = lml,\n",
    "                                           lml = -error) # This is just for function reasons\n",
    "\n",
    "error_posterior <- merge( x = error_posterior_incomplete,\n",
    "                          y = lmls_posterior_ff %>% select(pid, condition, scenario) %>% unique,\n",
    "                          by = c('pid', 'scenario'))\n",
    "\n",
    "print('Should be TRUE:')\n",
    "print(error_posterior %>% nrow == 7724)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove the non-compositional kernels AND leave only the best-fitting kernel for each (pid, scenario)\n",
    "best_fitting_per_pid_scenario <- function(lmls_ff) {\n",
    "   lmls_ff %>%\n",
    "    filter( kernel != 'l', kernel != 'p', kernel != 'r' ) %>%\n",
    "    group_by( pid, condition, scenario ) %>%\n",
    "    summarize( best_kernel = kernel[which.max(lml)],\n",
    "               lml         =    lml[which.max(lml)])  \n",
    "}\n",
    "\n",
    "best_fit_and_merge <- function(prior_data, posterior_data){\n",
    "    # Adding condition to the prior_data\n",
    "    prior_data$condition <- 'Prior'\n",
    "    \n",
    "    best_in_prior <- best_fitting_per_pid_scenario(prior_data)\n",
    "    best_in_posterior <- best_fitting_per_pid_scenario(posterior_data)\n",
    "\n",
    "    # Merging the best fitting compositions\n",
    "    aux_best_fitting_kernels <- merge(\n",
    "                                x = best_in_prior,\n",
    "                                y = best_in_posterior,\n",
    "                                by = c('pid', 'scenario'),\n",
    "                                suffixes = c('_prior', '_posterior')\n",
    "    )\n",
    "    \n",
    "    return(aux_best_fitting_kernels)\n",
    "}\n",
    "\n",
    "best_fitting_kernels <- best_fit_and_merge(lmls_prior_ff, error_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we have to check and calculate the proportions of match\n",
    "match_per_condition <- best_fitting_kernels %>%\n",
    "    mutate(match = (best_kernel_prior == best_kernel_posterior)) %>%\n",
    "    group_by(condition_posterior) %>%\n",
    "    summarize(match_proportion = bp2(match, alpha=0.05, round_n=3)[1], \n",
    "              lo_ci            = bp2(match, alpha=0.05, round_n=3)[2], \n",
    "              hi_ci            = bp2(match, alpha=0.05, round_n=3)[3])\n",
    "\n",
    "match_per_scenario <- best_fitting_kernels %>%\n",
    "    mutate(match = (best_kernel_prior == best_kernel_posterior)) %>%\n",
    "    group_by(scenario) %>%\n",
    "    summarize(match_proportion = bp2(match, alpha=0.05, round_n=3)[1], \n",
    "              lo_ci            = bp2(match, alpha=0.05, round_n=3)[2], \n",
    "              hi_ci            = bp2(match, alpha=0.05, round_n=3)[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Reference: 0.091\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>condition_posterior</th><th scope=col>match_proportion</th><th scope=col>lo_ci</th><th scope=col>hi_ci</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Posterior-Negative</td><td>0.139             </td><td>0.097             </td><td>0.185             </td></tr>\n",
       "\t<tr><td>Posterior-Positive</td><td>0.131             </td><td>0.088             </td><td>0.172             </td></tr>\n",
       "\t<tr><td>Posterior-Stable  </td><td>0.126             </td><td>0.084             </td><td>0.168             </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " condition\\_posterior & match\\_proportion & lo\\_ci & hi\\_ci\\\\\n",
       "\\hline\n",
       "\t Posterior-Negative & 0.139              & 0.097              & 0.185             \\\\\n",
       "\t Posterior-Positive & 0.131              & 0.088              & 0.172             \\\\\n",
       "\t Posterior-Stable   & 0.126              & 0.084              & 0.168             \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "condition_posterior | match_proportion | lo_ci | hi_ci | \n",
       "|---|---|---|\n",
       "| Posterior-Negative | 0.139              | 0.097              | 0.185              | \n",
       "| Posterior-Positive | 0.131              | 0.088              | 0.172              | \n",
       "| Posterior-Stable   | 0.126              | 0.084              | 0.168              | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  condition_posterior match_proportion lo_ci hi_ci\n",
       "1 Posterior-Negative  0.139            0.097 0.185\n",
       "2 Posterior-Positive  0.131            0.088 0.172\n",
       "3 Posterior-Stable    0.126            0.084 0.168"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>scenario</th><th scope=col>match_proportion</th><th scope=col>lo_ci</th><th scope=col>hi_ci</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>FB Friends </td><td>0.076      </td><td>0.034      </td><td>0.126      </td></tr>\n",
       "\t<tr><td>Gym members</td><td>0.169      </td><td>0.101      </td><td>0.235      </td></tr>\n",
       "\t<tr><td>Rain       </td><td>0.185      </td><td>0.118      </td><td>0.252      </td></tr>\n",
       "\t<tr><td>Salary     </td><td>0.126      </td><td>0.067      </td><td>0.185      </td></tr>\n",
       "\t<tr><td>Sales      </td><td>0.093      </td><td>0.042      </td><td>0.143      </td></tr>\n",
       "\t<tr><td>Temperature</td><td>0.143      </td><td>0.084      </td><td>0.210      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " scenario & match\\_proportion & lo\\_ci & hi\\_ci\\\\\n",
       "\\hline\n",
       "\t FB Friends  & 0.076       & 0.034       & 0.126      \\\\\n",
       "\t Gym members & 0.169       & 0.101       & 0.235      \\\\\n",
       "\t Rain        & 0.185       & 0.118       & 0.252      \\\\\n",
       "\t Salary      & 0.126       & 0.067       & 0.185      \\\\\n",
       "\t Sales       & 0.093       & 0.042       & 0.143      \\\\\n",
       "\t Temperature & 0.143       & 0.084       & 0.210      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "scenario | match_proportion | lo_ci | hi_ci | \n",
       "|---|---|---|---|---|---|\n",
       "| FB Friends  | 0.076       | 0.034       | 0.126       | \n",
       "| Gym members | 0.169       | 0.101       | 0.235       | \n",
       "| Rain        | 0.185       | 0.118       | 0.252       | \n",
       "| Salary      | 0.126       | 0.067       | 0.185       | \n",
       "| Sales       | 0.093       | 0.042       | 0.143       | \n",
       "| Temperature | 0.143       | 0.084       | 0.210       | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  scenario    match_proportion lo_ci hi_ci\n",
       "1 FB Friends  0.076            0.034 0.126\n",
       "2 Gym members 0.169            0.101 0.235\n",
       "3 Rain        0.185            0.118 0.252\n",
       "4 Salary      0.126            0.067 0.185\n",
       "5 Sales       0.093            0.042 0.143\n",
       "6 Temperature 0.143            0.084 0.210"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(paste('Reference:', round(1/11, 3)))\n",
    "\n",
    "match_per_condition\n",
    "match_per_scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Per condition (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>condition_posterior</th><th scope=col>x</th><th scope=col>n</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Posterior-Negative</td><td>33                </td><td>238               </td></tr>\n",
       "\t<tr><td>Posterior-Positive</td><td>31                </td><td>238               </td></tr>\n",
       "\t<tr><td>Posterior-Stable  </td><td>30                </td><td>238               </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " condition\\_posterior & x & n\\\\\n",
       "\\hline\n",
       "\t Posterior-Negative & 33                 & 238               \\\\\n",
       "\t Posterior-Positive & 31                 & 238               \\\\\n",
       "\t Posterior-Stable   & 30                 & 238               \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "condition_posterior | x | n | \n",
       "|---|---|---|\n",
       "| Posterior-Negative | 33                 | 238                | \n",
       "| Posterior-Positive | 31                 | 238                | \n",
       "| Posterior-Stable   | 30                 | 238                | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  condition_posterior x  n  \n",
       "1 Posterior-Negative  33 238\n",
       "2 Posterior-Positive  31 238\n",
       "3 Posterior-Stable    30 238"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_n_per_condition <- best_fitting_kernels %>%\n",
    "                        mutate(match = (best_kernel_prior == best_kernel_posterior)) %>%\n",
    "                        group_by(condition_posterior) %>%\n",
    "                        summarize(x = sum(match), n = length(match))\n",
    "\n",
    "x_n_per_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binom_test_special <- function (dataset, condition_name) {\n",
    "    x <- (dataset %>% filter(condition_posterior == condition_name))$x\n",
    "    n <- (dataset %>% filter(condition_posterior == condition_name))$n\n",
    "    \n",
    "    print(condition_name)\n",
    "    binom.test(x, n, p=1/11, alternative=\"two.sided\", conf.level=0.95)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Posterior-Negative\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\tOne Sample t-test\n",
       "\n",
       "data:  y\n",
       "t = 2.127, df = 237, p-value = 0.03446\n",
       "alternative hypothesis: true mean is not equal to 0.09090909\n",
       "95 percent confidence interval:\n",
       " 0.09443184 0.18287908\n",
       "sample estimates:\n",
       "mean of x \n",
       "0.1386555 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "binom_test_special_2 <- function (dataset, condition_name) {\n",
    "    y <- (best_fitting_kernels %>%\n",
    "                filter(condition_posterior == condition_name) %>%\n",
    "                mutate(match = (best_kernel_prior == best_kernel_posterior)))$match * 1\n",
    "    \n",
    "    print(condition_name)\n",
    "    #binom.test(x, n, p=1/11, alternative=\"two.sided\", conf.level=0.95)\n",
    "    t.test(y, mu = 1/11) # Ho: mu=3 \n",
    "}\n",
    "binom_test_special_2(x_n_per_condition, \"Posterior-Negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Posterior-Negative\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\tExact binomial test\n",
       "\n",
       "data:  x and n\n",
       "number of successes = 33, number of trials = 238, p-value = 0.01707\n",
       "alternative hypothesis: true probability of success is not equal to 0.09090909\n",
       "95 percent confidence interval:\n",
       " 0.09740411 0.18917909\n",
       "sample estimates:\n",
       "probability of success \n",
       "             0.1386555 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Posterior-Stable\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\tExact binomial test\n",
       "\n",
       "data:  x and n\n",
       "number of successes = 30, number of trials = 238, p-value = 0.06999\n",
       "alternative hypothesis: true probability of success is not equal to 0.09090909\n",
       "95 percent confidence interval:\n",
       " 0.08668616 0.17503235\n",
       "sample estimates:\n",
       "probability of success \n",
       "             0.1260504 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Posterior-Positive\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\tExact binomial test\n",
       "\n",
       "data:  x and n\n",
       "number of successes = 31, number of trials = 238, p-value = 0.04165\n",
       "alternative hypothesis: true probability of success is not equal to 0.09090909\n",
       "95 percent confidence interval:\n",
       " 0.09024432 0.17976189\n",
       "sample estimates:\n",
       "probability of success \n",
       "             0.1302521 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "binom_test_special(x_n_per_condition, \"Posterior-Negative\")\n",
    "binom_test_special(x_n_per_condition, \"Posterior-Stable\")\n",
    "binom_test_special(x_n_per_condition, \"Posterior-Positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### By scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>scenario</th><th scope=col>x</th><th scope=col>n</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>FB Friends </td><td> 9         </td><td>119        </td></tr>\n",
       "\t<tr><td>Gym members</td><td>20         </td><td>119        </td></tr>\n",
       "\t<tr><td>Rain       </td><td>22         </td><td>119        </td></tr>\n",
       "\t<tr><td>Salary     </td><td>15         </td><td>119        </td></tr>\n",
       "\t<tr><td>Sales      </td><td>11         </td><td>119        </td></tr>\n",
       "\t<tr><td>Temperature</td><td>17         </td><td>119        </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " scenario & x & n\\\\\n",
       "\\hline\n",
       "\t FB Friends  &  9          & 119        \\\\\n",
       "\t Gym members & 20          & 119        \\\\\n",
       "\t Rain        & 22          & 119        \\\\\n",
       "\t Salary      & 15          & 119        \\\\\n",
       "\t Sales       & 11          & 119        \\\\\n",
       "\t Temperature & 17          & 119        \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "scenario | x | n | \n",
       "|---|---|---|---|---|---|\n",
       "| FB Friends  |  9          | 119         | \n",
       "| Gym members | 20          | 119         | \n",
       "| Rain        | 22          | 119         | \n",
       "| Salary      | 15          | 119         | \n",
       "| Sales       | 11          | 119         | \n",
       "| Temperature | 17          | 119         | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  scenario    x  n  \n",
       "1 FB Friends   9 119\n",
       "2 Gym members 20 119\n",
       "3 Rain        22 119\n",
       "4 Salary      15 119\n",
       "5 Sales       11 119\n",
       "6 Temperature 17 119"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_n_per_scenario <- best_fitting_kernels %>%\n",
    "                        mutate(match = (best_kernel_prior == best_kernel_posterior)) %>%\n",
    "                        group_by(scenario) %>%\n",
    "                        summarize(x = sum(match), n = length(match))\n",
    "\n",
    "x_n_per_scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Temperature\"\n",
      "\n",
      "\tExact binomial test\n",
      "\n",
      "data:  x and n\n",
      "number of successes = 17, number of trials = 119, p-value = 0.0551\n",
      "alternative hypothesis: true probability of success is not equal to 0.09090909\n",
      "95 percent confidence interval:\n",
      " 0.0854768 0.2188484\n",
      "sample estimates:\n",
      "probability of success \n",
      "             0.1428571 \n",
      "\n",
      "[1] \"Rain\"\n",
      "\n",
      "\tExact binomial test\n",
      "\n",
      "data:  x and n\n",
      "number of successes = 22, number of trials = 119, p-value = 0.001187\n",
      "alternative hypothesis: true probability of success is not equal to 0.09090909\n",
      "95 percent confidence interval:\n",
      " 0.1196370 0.2664134\n",
      "sample estimates:\n",
      "probability of success \n",
      "             0.1848739 \n",
      "\n",
      "[1] \"Sales\"\n",
      "\n",
      "\tExact binomial test\n",
      "\n",
      "data:  x and n\n",
      "number of successes = 11, number of trials = 119, p-value = 0.8738\n",
      "alternative hypothesis: true probability of success is not equal to 0.09090909\n",
      "95 percent confidence interval:\n",
      " 0.04705217 0.15937705\n",
      "sample estimates:\n",
      "probability of success \n",
      "            0.09243697 \n",
      "\n",
      "[1] \"Gym members\"\n",
      "\n",
      "\tExact binomial test\n",
      "\n",
      "data:  x and n\n",
      "number of successes = 20, number of trials = 119, p-value = 0.006306\n",
      "alternative hypothesis: true probability of success is not equal to 0.09090909\n",
      "95 percent confidence interval:\n",
      " 0.1057877 0.2475626\n",
      "sample estimates:\n",
      "probability of success \n",
      "             0.1680672 \n",
      "\n",
      "[1] \"Salary\"\n",
      "\n",
      "\tExact binomial test\n",
      "\n",
      "data:  x and n\n",
      "number of successes = 15, number of trials = 119, p-value = 0.199\n",
      "alternative hypothesis: true probability of success is not equal to 0.09090909\n",
      "95 percent confidence interval:\n",
      " 0.07229736 0.19936700\n",
      "sample estimates:\n",
      "probability of success \n",
      "             0.1260504 \n",
      "\n",
      "[1] \"FB Friends\"\n",
      "\n",
      "\tExact binomial test\n",
      "\n",
      "data:  x and n\n",
      "number of successes = 9, number of trials = 119, p-value = 0.7487\n",
      "alternative hypothesis: true probability of success is not equal to 0.09090909\n",
      "95 percent confidence interval:\n",
      " 0.0351654 0.1387171\n",
      "sample estimates:\n",
      "probability of success \n",
      "            0.07563025 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "binom_test_special_scenario <- function (dataset, scenario_name) {\n",
    "    x <- (dataset %>% filter(scenario == scenario_name))$x\n",
    "    n <- (dataset %>% filter(scenario == scenario_name))$n\n",
    "    \n",
    "    print(scenario_name)\n",
    "    binom.test(x, n, p=1/11, alternative=\"two.sided\", conf.level=0.95)\n",
    "}\n",
    "\n",
    "for(scn in readable_scenarios){\n",
    "    print(binom_test_special_scenario(x_n_per_scenario, scn))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Posterior analysis, participants' data, proportion of match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  id = col_integer(),\n",
      "  kernel = col_character(),\n",
      "  lml = col_double(),\n",
      "  white_added = col_character(),\n",
      "  second_exception = col_character()\n",
      ")\n",
      "Warning message:\n",
      "\"Missing column names filled in: 'X1' [1]\"Parsed with column specification:\n",
      "cols(\n",
      "  X1 = col_integer(),\n",
      "  id = col_integer(),\n",
      "  pid = col_character(),\n",
      "  scenario = col_character(),\n",
      "  x = col_integer(),\n",
      "  y = col_double(),\n",
      "  condition = col_character()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Prior data\n",
    "lmls_prior_ff$condition <- 'Prior'\n",
    "\n",
    "# Posterior data (participants (i.e., no evidence))\n",
    "lmls_posterior_participants_ff <- get_filtered_data( \"output/minus-mean-treatment/results_posterior_participants_lmls.csv\",\n",
    "                                                     \"data/for_composititional_analysis_posterior.csv\" )\n",
    "\n",
    "# Readable kernel composition\n",
    "lmls_posterior_participants_ff$kernel <- readable_kernel(lmls_posterior_participants_ff$kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  id = col_integer(),\n",
      "  kernel = col_character(),\n",
      "  lml = col_double(),\n",
      "  white_added = col_character(),\n",
      "  second_exception = col_character()\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "1.43"
      ],
      "text/latex": [
       "1.43"
      ],
      "text/markdown": [
       "1.43"
      ],
      "text/plain": [
       "[1] 1.43"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Percentage of removed data points:\n",
    "((1 -\n",
    "lmls_posterior_participants_ff %>%\n",
    "    filter(kernel != 'l', kernel != 'p', kernel != 'r') %>%\n",
    "    nrow / \n",
    "read_csv('output/minus-mean-treatment/results_posterior_participants_lmls.csv') %>%\n",
    "    filter(kernel != 'l', kernel != 'p', kernel != 'r') %>%\n",
    "    nrow) * 100) %>%\n",
    "round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>scenario</th><th scope=col>match_proportion</th><th scope=col>lo_ci</th><th scope=col>hi_ci</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>FB Friends </td><td>0.312      </td><td>0.227      </td><td>0.395      </td></tr>\n",
       "\t<tr><td>Gym members</td><td>0.352      </td><td>0.269      </td><td>0.437      </td></tr>\n",
       "\t<tr><td>Rain       </td><td>0.529      </td><td>0.437      </td><td>0.622      </td></tr>\n",
       "\t<tr><td>Salary     </td><td>0.336      </td><td>0.252      </td><td>0.420      </td></tr>\n",
       "\t<tr><td>Sales      </td><td>0.143      </td><td>0.084      </td><td>0.210      </td></tr>\n",
       "\t<tr><td>Temperature</td><td>0.361      </td><td>0.277      </td><td>0.454      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " scenario & match\\_proportion & lo\\_ci & hi\\_ci\\\\\n",
       "\\hline\n",
       "\t FB Friends  & 0.312       & 0.227       & 0.395      \\\\\n",
       "\t Gym members & 0.352       & 0.269       & 0.437      \\\\\n",
       "\t Rain        & 0.529       & 0.437       & 0.622      \\\\\n",
       "\t Salary      & 0.336       & 0.252       & 0.420      \\\\\n",
       "\t Sales       & 0.143       & 0.084       & 0.210      \\\\\n",
       "\t Temperature & 0.361       & 0.277       & 0.454      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "scenario | match_proportion | lo_ci | hi_ci | \n",
       "|---|---|---|---|---|---|\n",
       "| FB Friends  | 0.312       | 0.227       | 0.395       | \n",
       "| Gym members | 0.352       | 0.269       | 0.437       | \n",
       "| Rain        | 0.529       | 0.437       | 0.622       | \n",
       "| Salary      | 0.336       | 0.252       | 0.420       | \n",
       "| Sales       | 0.143       | 0.084       | 0.210       | \n",
       "| Temperature | 0.361       | 0.277       | 0.454       | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  scenario    match_proportion lo_ci hi_ci\n",
       "1 FB Friends  0.312            0.227 0.395\n",
       "2 Gym members 0.352            0.269 0.437\n",
       "3 Rain        0.529            0.437 0.622\n",
       "4 Salary      0.336            0.252 0.420\n",
       "5 Sales       0.143            0.084 0.210\n",
       "6 Temperature 0.361            0.277 0.454"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_fitting_kernels <- best_fit_and_merge(lmls_prior_ff, \n",
    "                                           lmls_posterior_participants_ff)\n",
    "\n",
    "# Now we have to check and calculate the proportions of match\n",
    "match_per_scenario <- best_fitting_kernels %>%\n",
    "    mutate(match = (best_kernel_prior == best_kernel_posterior)) %>%\n",
    "    group_by(scenario) %>%\n",
    "    summarize(match_proportion = bp2(match, alpha=0.05, round_n=3)[1], \n",
    "              lo_ci            = bp2(match, alpha=0.05, round_n=3)[2], \n",
    "              hi_ci            = bp2(match, alpha=0.05, round_n=3)[3])\n",
    "\n",
    "match_per_scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Statistical tests per scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>scenario</th><th scope=col>x</th><th scope=col>n</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>FB Friends </td><td>37         </td><td>119        </td></tr>\n",
       "\t<tr><td>Gym members</td><td>42         </td><td>119        </td></tr>\n",
       "\t<tr><td>Rain       </td><td>63         </td><td>119        </td></tr>\n",
       "\t<tr><td>Salary     </td><td>40         </td><td>119        </td></tr>\n",
       "\t<tr><td>Sales      </td><td>17         </td><td>119        </td></tr>\n",
       "\t<tr><td>Temperature</td><td>43         </td><td>119        </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " scenario & x & n\\\\\n",
       "\\hline\n",
       "\t FB Friends  & 37          & 119        \\\\\n",
       "\t Gym members & 42          & 119        \\\\\n",
       "\t Rain        & 63          & 119        \\\\\n",
       "\t Salary      & 40          & 119        \\\\\n",
       "\t Sales       & 17          & 119        \\\\\n",
       "\t Temperature & 43          & 119        \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "scenario | x | n | \n",
       "|---|---|---|---|---|---|\n",
       "| FB Friends  | 37          | 119         | \n",
       "| Gym members | 42          | 119         | \n",
       "| Rain        | 63          | 119         | \n",
       "| Salary      | 40          | 119         | \n",
       "| Sales       | 17          | 119         | \n",
       "| Temperature | 43          | 119         | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  scenario    x  n  \n",
       "1 FB Friends  37 119\n",
       "2 Gym members 42 119\n",
       "3 Rain        63 119\n",
       "4 Salary      40 119\n",
       "5 Sales       17 119\n",
       "6 Temperature 43 119"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Temperature\"\n",
      "[1] \"Rain\"\n",
      "[1] \"Sales\"\n",
      "[1] \"Gym members\"\n",
      "[1] \"Salary\"\n",
      "[1] \"FB Friends\"\n",
      "[1] \"$\\\\hat{p}=0.36$ ($x=43, n=119, p<0.001$) for the Temperature data, $\\\\hat{p}=0.53$ ($x=63, n=119, p<0.001$) for the Rain data, $\\\\hat{p}=0.14$ ($x=17, n=119, p>0.05$) for the Sales data, $\\\\hat{p}=0.35$ ($x=42, n=119, p<0.001$) for the Gym members data, $\\\\hat{p}=0.34$ ($x=40, n=119, p<0.001$) for the Salary data, $\\\\hat{p}=0.31$ ($x=37, n=119, p<0.001$) for the Facebook friends data.\"\n"
     ]
    }
   ],
   "source": [
    "x_n_per_scenario <- best_fitting_kernels %>%\n",
    "                        mutate(match = (best_kernel_prior == best_kernel_posterior)) %>%\n",
    "                        group_by(scenario) %>%\n",
    "                        summarize(x = sum(match), n = length(match))\n",
    "\n",
    "x_n_per_scenario\n",
    "\n",
    "for(scn in readable_scenarios){\n",
    "    #print(binom_test_special_scenario(x_n_per_scenario, scn))\n",
    "}\n",
    "\n",
    "# Readable:\n",
    "to_report = ''\n",
    "\n",
    "for(scn in readable_scenarios){\n",
    "    \n",
    "    test_results_per_scenario <- binom_test_special_scenario(x_n_per_scenario, scn)\n",
    "    \n",
    "    proportion <- test_results_per_scenario[[5]][[1]] %>% round(2)\n",
    "    \n",
    "    df <- test_results_per_scenario[[2]]\n",
    "    p_val <- ifelse(test_results_per_scenario[[3]] < 0.001, \n",
    "                \"<0.001\", \n",
    "                test_results_per_scenario[[3]])\n",
    "    \n",
    "    p_val <- ifelse(p_val > 0.05, \n",
    "                \">0.05\", \n",
    "                p_val)\n",
    "    \n",
    "    t <- test_results_per_scenario[[1]] %>% round(2)\n",
    "    \n",
    "    #t_string <- paste0(\"$r=\", proportion, \"$ ($t(\", df, \")=\", t, \"$, $p\", p_val, \"$)\")\n",
    "    t_string <- paste0(\"$\\\\hat{p}=\", proportion, \"$ ($x=\", t, \", n=\", df, \", p\", p_val, \"$)\")\n",
    "    \n",
    "    to_return_scenario <- paste0(t_string, \" for the \", scn, \" data, \")\n",
    "    \n",
    "    to_report <- paste0(to_report, to_return_scenario)\n",
    "    \n",
    "    to_report = gsub(\"FB Friends data, \",\"Facebook friends data.\", to_report)\n",
    "}\n",
    "\n",
    "print(to_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
